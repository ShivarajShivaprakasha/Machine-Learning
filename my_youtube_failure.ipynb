{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my-youtube-failure.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivarajShivaprakasha/Machine-Learning/blob/main/my_youtube_failure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GclBYVg2Gy1_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/youtube-channel-comparison - youtube-channel-comparison.csv')"
      ],
      "metadata": {
        "id": "SRjiQAj0HD2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n5GPXegkHHBN",
        "outputId": "2b0c44e3-c36d-4d66-9612-e550eb9e511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          channel name  views   subs  last 30 days views  num videos  \\\n",
              "0          Data School   9.73  193.0               106.0         138   \n",
              "1        Bhavesh Bhatt   2.72   37.4                72.7         292   \n",
              "2  Unfold Data Science   1.72   27.9               123.0         369   \n",
              "3      Abhishek Thakur   1.74   69.8                59.6         139   \n",
              "4            AppliedAI  13.20   77.9                98.6         497   \n",
              "\n",
              "      how old  \n",
              "0  01/05/2014  \n",
              "1  12/11/2017  \n",
              "2  02/08/2019  \n",
              "3  26/12/2019  \n",
              "4  28/09/2017  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ce79d84-36c4-4a01-9d26-e02dfc424dac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views</th>\n",
              "      <th>subs</th>\n",
              "      <th>last 30 days views</th>\n",
              "      <th>num videos</th>\n",
              "      <th>how old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>9.73</td>\n",
              "      <td>193.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>138</td>\n",
              "      <td>01/05/2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>2.72</td>\n",
              "      <td>37.4</td>\n",
              "      <td>72.7</td>\n",
              "      <td>292</td>\n",
              "      <td>12/11/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>1.72</td>\n",
              "      <td>27.9</td>\n",
              "      <td>123.0</td>\n",
              "      <td>369</td>\n",
              "      <td>02/08/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>1.74</td>\n",
              "      <td>69.8</td>\n",
              "      <td>59.6</td>\n",
              "      <td>139</td>\n",
              "      <td>26/12/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>13.20</td>\n",
              "      <td>77.9</td>\n",
              "      <td>98.6</td>\n",
              "      <td>497</td>\n",
              "      <td>28/09/2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ce79d84-36c4-4a01-9d26-e02dfc424dac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ce79d84-36c4-4a01-9d26-e02dfc424dac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ce79d84-36c4-4a01-9d26-e02dfc424dac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M1zZEhCHILO",
        "outputId": "a22da617-a486-444b-fb27-6b9f9c261fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['views'] = df['views'] * 1000000\n",
        "df['subs'] = df['subs'] * 1000\n",
        "df['last 30 days views'] = df['last 30 days views'] * 1000\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pDMCSN0LHMN1",
        "outputId": "ce53e5ae-fb1e-44db-bd65-e8989fa4e215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name        views       subs  last 30 days views  \\\n",
              "0                 Data School    9730000.0   193000.0            106000.0   \n",
              "1               Bhavesh Bhatt    2720000.0    37400.0             72700.0   \n",
              "2         Unfold Data Science    1720000.0    27900.0            123000.0   \n",
              "3             Abhishek Thakur    1740000.0    69800.0             59600.0   \n",
              "4                   AppliedAI   13200000.0    77900.0             98600.0   \n",
              "5       5 minutes engineering   37900000.0   303000.0           1610000.0   \n",
              "6             Serrano Academy    4770000.0    96400.0             70200.0   \n",
              "7                  Krish Naik   51100000.0   556000.0           1650000.0   \n",
              "8                  Codebasics   35000000.0   557000.0           1470000.0   \n",
              "9                   Statquest   35900000.0   702000.0           1390000.0   \n",
              "10                    CampusX    1500000.0    18000.0            198000.0   \n",
              "11          Satyajit Pattnaik     480000.0    19400.0             56400.0   \n",
              "12              Daniel Bourke    5280000.0   112000.0             84900.0   \n",
              "13                 Deeplizard    9330000.0   117000.0            167000.0   \n",
              "14                    Ken Jee    6060000.0   195000.0            153000.0   \n",
              "15            Python Engineer    6960000.0   115000.0            823000.0   \n",
              "16                  KGPTalkie    4450000.0    39800.0             88800.0   \n",
              "17             AI Engineering    1950000.0    62200.0             61400.0   \n",
              "18            Nicolas Renotte    3440000.0    67900.0            312000.0   \n",
              "19                 Siddaharan    1020000.0    48600.0            118000.0   \n",
              "20       Indian AI Production    3530000.0    31900.0            119000.0   \n",
              "21          The AI University    1330000.0    24000.0             46200.0   \n",
              "22              Harshit Tyagi     180000.0     8030.0              5240.0   \n",
              "23           Developer Ashish     320000.0    16200.0             13300.0   \n",
              "24            Normalized Nerd    1300000.0    30600.0            117000.0   \n",
              "25               Smitha Kolan    1090000.0    37800.0             45400.0   \n",
              "26         Shashank Kalanithi    3260000.0    81900.0            202000.0   \n",
              "27              DigitalSreeni    2570000.0    38400.0            198000.0   \n",
              "28             Brandon Rohrer    4390000.0    77300.0             46500.0   \n",
              "29                  Ranji Raj    6210000.0    42300.0            116000.0   \n",
              "30          Abhishek Agarrwal    7430000.0        NaN            196000.0   \n",
              "31            Deeplearning.ai   11300000.0   170000.0            181000.0   \n",
              "32     Deep Learning in Hindi     330000.0     4470.0              8410.0   \n",
              "33              Fahad Hussain    1310000.0    16100.0             46500.0   \n",
              "34           Data Science Jay     970000.0    22400.0             66600.0   \n",
              "35              Sundas Khalid    2150000.0    64700.0            174000.0   \n",
              "36           Seattle Data Guy    1200000.0    26000.0            108000.0   \n",
              "37             Data Professor    2790000.0   116000.0            130000.0   \n",
              "38                 Tina Huang   10800000.0   294000.0            651000.0   \n",
              "39  Data Science Career Coach    1540000.0    28000.0            124000.0   \n",
              "40                    Sentdex  101000000.0  1110000.0            588000.0   \n",
              "41          Data Science Dojo    4690000.0    82700.0             66500.0   \n",
              "42     Data Science Tutorials    3890000.0    38100.0            130000.0   \n",
              "43              Brandon Foltz   23200000.0   262000.0            179000.0   \n",
              "44                   Datacamp   20800000.0   129000.0            627000.0   \n",
              "45               The Semiclon    2170000.0    23500.0             20300.0   \n",
              "46                 Ritvikmath    5780000.0    79900.0            215000.0   \n",
              "47                     kaggle    2940000.0   103000.0             55600.0   \n",
              "48                    ineuron    1130000.0    41700.0            705000.0   \n",
              "49                Springboard    3900000.0    53000.0            141000.0   \n",
              "50                     Jovian     950000.0    27000.0             59700.0   \n",
              "\n",
              "    num videos     how old  \n",
              "0          138  01/05/2014  \n",
              "1          292  12/11/2017  \n",
              "2          369  02/08/2019  \n",
              "3          139  26/12/2019  \n",
              "4          497  28/09/2017  \n",
              "5         1390  17/08/2018  \n",
              "6           43  09/09/2016  \n",
              "7         1360  25/11/2017  \n",
              "8          493  20/12/2015  \n",
              "9          217  03/02/2015  \n",
              "10        1100  22/09/2019  \n",
              "11         305  25/06/2020  \n",
              "12         291  12/06/2018  \n",
              "13         307  19/11/2017  \n",
              "14         230  19/11/2017  \n",
              "15         163  26/05/2019  \n",
              "16         593  17/05/2018  \n",
              "17         261  08/09/2019  \n",
              "18         181  30/01/2019  \n",
              "19         138  24/01/2021  \n",
              "20         342  01/06/2019  \n",
              "21         332  28/01/2019  \n",
              "22          44  23/03/2020  \n",
              "23          39  06/04/2020  \n",
              "24          88  11/02/2019  \n",
              "25          66  15/09/2019  \n",
              "26         111  06/05/2020  \n",
              "27         316  06/05/2019  \n",
              "28         145  23/05/2016  \n",
              "29         539  24/06/2016  \n",
              "30        1190  26/10/2016  \n",
              "31         219  26/08/2017  \n",
              "32         201  30/06/2019  \n",
              "33         741  20/07/2019  \n",
              "34          95  28/01/2020  \n",
              "35          51  21/08/2020  \n",
              "36         122  24/05/2018  \n",
              "37         272  20/08/2019  \n",
              "38          92  22/07/2020  \n",
              "39        1410  21/01/2019  \n",
              "40        1250  17/05/2013  \n",
              "41         297  07/01/2017  \n",
              "42         869  26/09/2016  \n",
              "43         259  31/07/2012  \n",
              "44        1240  04/12/2015  \n",
              "45          46  19/01/2017  \n",
              "46         415  22/03/2015  \n",
              "47         346  17/03/2018  \n",
              "48         193  07/01/2020  \n",
              "49         108  25/04/2019  \n",
              "50         148  11/07/2019  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d8ff644-7d45-4379-b132-2de8ae2ad334\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views</th>\n",
              "      <th>subs</th>\n",
              "      <th>last 30 days views</th>\n",
              "      <th>num videos</th>\n",
              "      <th>how old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>9730000.0</td>\n",
              "      <td>193000.0</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>01/05/2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>2720000.0</td>\n",
              "      <td>37400.0</td>\n",
              "      <td>72700.0</td>\n",
              "      <td>292</td>\n",
              "      <td>12/11/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>1720000.0</td>\n",
              "      <td>27900.0</td>\n",
              "      <td>123000.0</td>\n",
              "      <td>369</td>\n",
              "      <td>02/08/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>1740000.0</td>\n",
              "      <td>69800.0</td>\n",
              "      <td>59600.0</td>\n",
              "      <td>139</td>\n",
              "      <td>26/12/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>13200000.0</td>\n",
              "      <td>77900.0</td>\n",
              "      <td>98600.0</td>\n",
              "      <td>497</td>\n",
              "      <td>28/09/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>37900000.0</td>\n",
              "      <td>303000.0</td>\n",
              "      <td>1610000.0</td>\n",
              "      <td>1390</td>\n",
              "      <td>17/08/2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>4770000.0</td>\n",
              "      <td>96400.0</td>\n",
              "      <td>70200.0</td>\n",
              "      <td>43</td>\n",
              "      <td>09/09/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>51100000.0</td>\n",
              "      <td>556000.0</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>1360</td>\n",
              "      <td>25/11/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>35000000.0</td>\n",
              "      <td>557000.0</td>\n",
              "      <td>1470000.0</td>\n",
              "      <td>493</td>\n",
              "      <td>20/12/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>35900000.0</td>\n",
              "      <td>702000.0</td>\n",
              "      <td>1390000.0</td>\n",
              "      <td>217</td>\n",
              "      <td>03/02/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>1100</td>\n",
              "      <td>22/09/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>480000.0</td>\n",
              "      <td>19400.0</td>\n",
              "      <td>56400.0</td>\n",
              "      <td>305</td>\n",
              "      <td>25/06/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>5280000.0</td>\n",
              "      <td>112000.0</td>\n",
              "      <td>84900.0</td>\n",
              "      <td>291</td>\n",
              "      <td>12/06/2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>9330000.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>167000.0</td>\n",
              "      <td>307</td>\n",
              "      <td>19/11/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>6060000.0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>153000.0</td>\n",
              "      <td>230</td>\n",
              "      <td>19/11/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>6960000.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>823000.0</td>\n",
              "      <td>163</td>\n",
              "      <td>26/05/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>4450000.0</td>\n",
              "      <td>39800.0</td>\n",
              "      <td>88800.0</td>\n",
              "      <td>593</td>\n",
              "      <td>17/05/2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>1950000.0</td>\n",
              "      <td>62200.0</td>\n",
              "      <td>61400.0</td>\n",
              "      <td>261</td>\n",
              "      <td>08/09/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>3440000.0</td>\n",
              "      <td>67900.0</td>\n",
              "      <td>312000.0</td>\n",
              "      <td>181</td>\n",
              "      <td>30/01/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>1020000.0</td>\n",
              "      <td>48600.0</td>\n",
              "      <td>118000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>24/01/2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>3530000.0</td>\n",
              "      <td>31900.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>342</td>\n",
              "      <td>01/06/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>1330000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>46200.0</td>\n",
              "      <td>332</td>\n",
              "      <td>28/01/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>8030.0</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>44</td>\n",
              "      <td>23/03/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>320000.0</td>\n",
              "      <td>16200.0</td>\n",
              "      <td>13300.0</td>\n",
              "      <td>39</td>\n",
              "      <td>06/04/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>1300000.0</td>\n",
              "      <td>30600.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>88</td>\n",
              "      <td>11/02/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>1090000.0</td>\n",
              "      <td>37800.0</td>\n",
              "      <td>45400.0</td>\n",
              "      <td>66</td>\n",
              "      <td>15/09/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>3260000.0</td>\n",
              "      <td>81900.0</td>\n",
              "      <td>202000.0</td>\n",
              "      <td>111</td>\n",
              "      <td>06/05/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>2570000.0</td>\n",
              "      <td>38400.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>316</td>\n",
              "      <td>06/05/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>4390000.0</td>\n",
              "      <td>77300.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>145</td>\n",
              "      <td>23/05/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>6210000.0</td>\n",
              "      <td>42300.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>539</td>\n",
              "      <td>24/06/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>7430000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1190</td>\n",
              "      <td>26/10/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>11300000.0</td>\n",
              "      <td>170000.0</td>\n",
              "      <td>181000.0</td>\n",
              "      <td>219</td>\n",
              "      <td>26/08/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>330000.0</td>\n",
              "      <td>4470.0</td>\n",
              "      <td>8410.0</td>\n",
              "      <td>201</td>\n",
              "      <td>30/06/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>1310000.0</td>\n",
              "      <td>16100.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>741</td>\n",
              "      <td>20/07/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>970000.0</td>\n",
              "      <td>22400.0</td>\n",
              "      <td>66600.0</td>\n",
              "      <td>95</td>\n",
              "      <td>28/01/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>2150000.0</td>\n",
              "      <td>64700.0</td>\n",
              "      <td>174000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>21/08/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>1200000.0</td>\n",
              "      <td>26000.0</td>\n",
              "      <td>108000.0</td>\n",
              "      <td>122</td>\n",
              "      <td>24/05/2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>2790000.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>272</td>\n",
              "      <td>20/08/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>10800000.0</td>\n",
              "      <td>294000.0</td>\n",
              "      <td>651000.0</td>\n",
              "      <td>92</td>\n",
              "      <td>22/07/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1540000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>124000.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>21/01/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>101000000.0</td>\n",
              "      <td>1110000.0</td>\n",
              "      <td>588000.0</td>\n",
              "      <td>1250</td>\n",
              "      <td>17/05/2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>4690000.0</td>\n",
              "      <td>82700.0</td>\n",
              "      <td>66500.0</td>\n",
              "      <td>297</td>\n",
              "      <td>07/01/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>3890000.0</td>\n",
              "      <td>38100.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>869</td>\n",
              "      <td>26/09/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>23200000.0</td>\n",
              "      <td>262000.0</td>\n",
              "      <td>179000.0</td>\n",
              "      <td>259</td>\n",
              "      <td>31/07/2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>20800000.0</td>\n",
              "      <td>129000.0</td>\n",
              "      <td>627000.0</td>\n",
              "      <td>1240</td>\n",
              "      <td>04/12/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>2170000.0</td>\n",
              "      <td>23500.0</td>\n",
              "      <td>20300.0</td>\n",
              "      <td>46</td>\n",
              "      <td>19/01/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>5780000.0</td>\n",
              "      <td>79900.0</td>\n",
              "      <td>215000.0</td>\n",
              "      <td>415</td>\n",
              "      <td>22/03/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>2940000.0</td>\n",
              "      <td>103000.0</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>346</td>\n",
              "      <td>17/03/2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>1130000.0</td>\n",
              "      <td>41700.0</td>\n",
              "      <td>705000.0</td>\n",
              "      <td>193</td>\n",
              "      <td>07/01/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>3900000.0</td>\n",
              "      <td>53000.0</td>\n",
              "      <td>141000.0</td>\n",
              "      <td>108</td>\n",
              "      <td>25/04/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>950000.0</td>\n",
              "      <td>27000.0</td>\n",
              "      <td>59700.0</td>\n",
              "      <td>148</td>\n",
              "      <td>11/07/2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8ff644-7d45-4379-b132-2de8ae2ad334')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d8ff644-7d45-4379-b132-2de8ae2ad334 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d8ff644-7d45-4379-b132-2de8ae2ad334');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['how old'] = pd.to_datetime(df['how old'])\n",
        "basedate = pd.Timestamp('2022-01-28')\n",
        "df['old'] = (basedate - df['how old']).dt.days\n",
        "df.drop(columns=['how old'],inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YJdGteI9HQXh",
        "outputId": "e98495d5-f1c9-4735-ec5e-0f4de49bcd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name        views       subs  last 30 days views  \\\n",
              "0                 Data School    9730000.0   193000.0            106000.0   \n",
              "1               Bhavesh Bhatt    2720000.0    37400.0             72700.0   \n",
              "2         Unfold Data Science    1720000.0    27900.0            123000.0   \n",
              "3             Abhishek Thakur    1740000.0    69800.0             59600.0   \n",
              "4                   AppliedAI   13200000.0    77900.0             98600.0   \n",
              "5       5 minutes engineering   37900000.0   303000.0           1610000.0   \n",
              "6             Serrano Academy    4770000.0    96400.0             70200.0   \n",
              "7                  Krish Naik   51100000.0   556000.0           1650000.0   \n",
              "8                  Codebasics   35000000.0   557000.0           1470000.0   \n",
              "9                   Statquest   35900000.0   702000.0           1390000.0   \n",
              "10                    CampusX    1500000.0    18000.0            198000.0   \n",
              "11          Satyajit Pattnaik     480000.0    19400.0             56400.0   \n",
              "12              Daniel Bourke    5280000.0   112000.0             84900.0   \n",
              "13                 Deeplizard    9330000.0   117000.0            167000.0   \n",
              "14                    Ken Jee    6060000.0   195000.0            153000.0   \n",
              "15            Python Engineer    6960000.0   115000.0            823000.0   \n",
              "16                  KGPTalkie    4450000.0    39800.0             88800.0   \n",
              "17             AI Engineering    1950000.0    62200.0             61400.0   \n",
              "18            Nicolas Renotte    3440000.0    67900.0            312000.0   \n",
              "19                 Siddaharan    1020000.0    48600.0            118000.0   \n",
              "20       Indian AI Production    3530000.0    31900.0            119000.0   \n",
              "21          The AI University    1330000.0    24000.0             46200.0   \n",
              "22              Harshit Tyagi     180000.0     8030.0              5240.0   \n",
              "23           Developer Ashish     320000.0    16200.0             13300.0   \n",
              "24            Normalized Nerd    1300000.0    30600.0            117000.0   \n",
              "25               Smitha Kolan    1090000.0    37800.0             45400.0   \n",
              "26         Shashank Kalanithi    3260000.0    81900.0            202000.0   \n",
              "27              DigitalSreeni    2570000.0    38400.0            198000.0   \n",
              "28             Brandon Rohrer    4390000.0    77300.0             46500.0   \n",
              "29                  Ranji Raj    6210000.0    42300.0            116000.0   \n",
              "30          Abhishek Agarrwal    7430000.0        NaN            196000.0   \n",
              "31            Deeplearning.ai   11300000.0   170000.0            181000.0   \n",
              "32     Deep Learning in Hindi     330000.0     4470.0              8410.0   \n",
              "33              Fahad Hussain    1310000.0    16100.0             46500.0   \n",
              "34           Data Science Jay     970000.0    22400.0             66600.0   \n",
              "35              Sundas Khalid    2150000.0    64700.0            174000.0   \n",
              "36           Seattle Data Guy    1200000.0    26000.0            108000.0   \n",
              "37             Data Professor    2790000.0   116000.0            130000.0   \n",
              "38                 Tina Huang   10800000.0   294000.0            651000.0   \n",
              "39  Data Science Career Coach    1540000.0    28000.0            124000.0   \n",
              "40                    Sentdex  101000000.0  1110000.0            588000.0   \n",
              "41          Data Science Dojo    4690000.0    82700.0             66500.0   \n",
              "42     Data Science Tutorials    3890000.0    38100.0            130000.0   \n",
              "43              Brandon Foltz   23200000.0   262000.0            179000.0   \n",
              "44                   Datacamp   20800000.0   129000.0            627000.0   \n",
              "45               The Semiclon    2170000.0    23500.0             20300.0   \n",
              "46                 Ritvikmath    5780000.0    79900.0            215000.0   \n",
              "47                     kaggle    2940000.0   103000.0             55600.0   \n",
              "48                    ineuron    1130000.0    41700.0            705000.0   \n",
              "49                Springboard    3900000.0    53000.0            141000.0   \n",
              "50                     Jovian     950000.0    27000.0             59700.0   \n",
              "\n",
              "    num videos   old  \n",
              "0          138  2945  \n",
              "1          292  1509  \n",
              "2          369  1085  \n",
              "3          139   764  \n",
              "4          497  1583  \n",
              "5         1390  1260  \n",
              "6           43  1967  \n",
              "7         1360  1525  \n",
              "8          493  2231  \n",
              "9          217  2524  \n",
              "10        1100   859  \n",
              "11         305   582  \n",
              "12         291  1149  \n",
              "13         307  1531  \n",
              "14         230  1531  \n",
              "15         163   978  \n",
              "16         593  1352  \n",
              "17         261   903  \n",
              "18         181  1094  \n",
              "19         138   369  \n",
              "20         342  1118  \n",
              "21         332  1096  \n",
              "22          44   676  \n",
              "23          39   603  \n",
              "24          88   818  \n",
              "25          66   866  \n",
              "26         111   602  \n",
              "27         316   968  \n",
              "28         145  2076  \n",
              "29         539  2044  \n",
              "30        1190  1920  \n",
              "31         219  1616  \n",
              "32         201   943  \n",
              "33         741   923  \n",
              "34          95   731  \n",
              "35          51   525  \n",
              "36         122  1345  \n",
              "37         272   892  \n",
              "38          92   555  \n",
              "39        1410  1103  \n",
              "40        1250  3178  \n",
              "41         297  1672  \n",
              "42         869  1950  \n",
              "43         259  3468  \n",
              "44        1240  2483  \n",
              "45          46  1835  \n",
              "46         415  2504  \n",
              "47         346  1413  \n",
              "48         193   576  \n",
              "49         108  1009  \n",
              "50         148   813  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cf3ce70-a8d7-4879-93ee-df95bbada269\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views</th>\n",
              "      <th>subs</th>\n",
              "      <th>last 30 days views</th>\n",
              "      <th>num videos</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>9730000.0</td>\n",
              "      <td>193000.0</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>2945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>2720000.0</td>\n",
              "      <td>37400.0</td>\n",
              "      <td>72700.0</td>\n",
              "      <td>292</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>1720000.0</td>\n",
              "      <td>27900.0</td>\n",
              "      <td>123000.0</td>\n",
              "      <td>369</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>1740000.0</td>\n",
              "      <td>69800.0</td>\n",
              "      <td>59600.0</td>\n",
              "      <td>139</td>\n",
              "      <td>764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>13200000.0</td>\n",
              "      <td>77900.0</td>\n",
              "      <td>98600.0</td>\n",
              "      <td>497</td>\n",
              "      <td>1583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>37900000.0</td>\n",
              "      <td>303000.0</td>\n",
              "      <td>1610000.0</td>\n",
              "      <td>1390</td>\n",
              "      <td>1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>4770000.0</td>\n",
              "      <td>96400.0</td>\n",
              "      <td>70200.0</td>\n",
              "      <td>43</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>51100000.0</td>\n",
              "      <td>556000.0</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>1360</td>\n",
              "      <td>1525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>35000000.0</td>\n",
              "      <td>557000.0</td>\n",
              "      <td>1470000.0</td>\n",
              "      <td>493</td>\n",
              "      <td>2231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>35900000.0</td>\n",
              "      <td>702000.0</td>\n",
              "      <td>1390000.0</td>\n",
              "      <td>217</td>\n",
              "      <td>2524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>1100</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>480000.0</td>\n",
              "      <td>19400.0</td>\n",
              "      <td>56400.0</td>\n",
              "      <td>305</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>5280000.0</td>\n",
              "      <td>112000.0</td>\n",
              "      <td>84900.0</td>\n",
              "      <td>291</td>\n",
              "      <td>1149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>9330000.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>167000.0</td>\n",
              "      <td>307</td>\n",
              "      <td>1531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>6060000.0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>153000.0</td>\n",
              "      <td>230</td>\n",
              "      <td>1531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>6960000.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>823000.0</td>\n",
              "      <td>163</td>\n",
              "      <td>978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>4450000.0</td>\n",
              "      <td>39800.0</td>\n",
              "      <td>88800.0</td>\n",
              "      <td>593</td>\n",
              "      <td>1352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>1950000.0</td>\n",
              "      <td>62200.0</td>\n",
              "      <td>61400.0</td>\n",
              "      <td>261</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>3440000.0</td>\n",
              "      <td>67900.0</td>\n",
              "      <td>312000.0</td>\n",
              "      <td>181</td>\n",
              "      <td>1094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>1020000.0</td>\n",
              "      <td>48600.0</td>\n",
              "      <td>118000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>3530000.0</td>\n",
              "      <td>31900.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>342</td>\n",
              "      <td>1118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>1330000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>46200.0</td>\n",
              "      <td>332</td>\n",
              "      <td>1096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>8030.0</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>44</td>\n",
              "      <td>676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>320000.0</td>\n",
              "      <td>16200.0</td>\n",
              "      <td>13300.0</td>\n",
              "      <td>39</td>\n",
              "      <td>603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>1300000.0</td>\n",
              "      <td>30600.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>88</td>\n",
              "      <td>818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>1090000.0</td>\n",
              "      <td>37800.0</td>\n",
              "      <td>45400.0</td>\n",
              "      <td>66</td>\n",
              "      <td>866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>3260000.0</td>\n",
              "      <td>81900.0</td>\n",
              "      <td>202000.0</td>\n",
              "      <td>111</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>2570000.0</td>\n",
              "      <td>38400.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>316</td>\n",
              "      <td>968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>4390000.0</td>\n",
              "      <td>77300.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>145</td>\n",
              "      <td>2076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>6210000.0</td>\n",
              "      <td>42300.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>539</td>\n",
              "      <td>2044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>7430000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1190</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>11300000.0</td>\n",
              "      <td>170000.0</td>\n",
              "      <td>181000.0</td>\n",
              "      <td>219</td>\n",
              "      <td>1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>330000.0</td>\n",
              "      <td>4470.0</td>\n",
              "      <td>8410.0</td>\n",
              "      <td>201</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>1310000.0</td>\n",
              "      <td>16100.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>741</td>\n",
              "      <td>923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>970000.0</td>\n",
              "      <td>22400.0</td>\n",
              "      <td>66600.0</td>\n",
              "      <td>95</td>\n",
              "      <td>731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>2150000.0</td>\n",
              "      <td>64700.0</td>\n",
              "      <td>174000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>1200000.0</td>\n",
              "      <td>26000.0</td>\n",
              "      <td>108000.0</td>\n",
              "      <td>122</td>\n",
              "      <td>1345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>2790000.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>272</td>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>10800000.0</td>\n",
              "      <td>294000.0</td>\n",
              "      <td>651000.0</td>\n",
              "      <td>92</td>\n",
              "      <td>555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1540000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>124000.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>101000000.0</td>\n",
              "      <td>1110000.0</td>\n",
              "      <td>588000.0</td>\n",
              "      <td>1250</td>\n",
              "      <td>3178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>4690000.0</td>\n",
              "      <td>82700.0</td>\n",
              "      <td>66500.0</td>\n",
              "      <td>297</td>\n",
              "      <td>1672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>3890000.0</td>\n",
              "      <td>38100.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>869</td>\n",
              "      <td>1950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>23200000.0</td>\n",
              "      <td>262000.0</td>\n",
              "      <td>179000.0</td>\n",
              "      <td>259</td>\n",
              "      <td>3468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>20800000.0</td>\n",
              "      <td>129000.0</td>\n",
              "      <td>627000.0</td>\n",
              "      <td>1240</td>\n",
              "      <td>2483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>2170000.0</td>\n",
              "      <td>23500.0</td>\n",
              "      <td>20300.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>5780000.0</td>\n",
              "      <td>79900.0</td>\n",
              "      <td>215000.0</td>\n",
              "      <td>415</td>\n",
              "      <td>2504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>2940000.0</td>\n",
              "      <td>103000.0</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>346</td>\n",
              "      <td>1413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>1130000.0</td>\n",
              "      <td>41700.0</td>\n",
              "      <td>705000.0</td>\n",
              "      <td>193</td>\n",
              "      <td>576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>3900000.0</td>\n",
              "      <td>53000.0</td>\n",
              "      <td>141000.0</td>\n",
              "      <td>108</td>\n",
              "      <td>1009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>950000.0</td>\n",
              "      <td>27000.0</td>\n",
              "      <td>59700.0</td>\n",
              "      <td>148</td>\n",
              "      <td>813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cf3ce70-a8d7-4879-93ee-df95bbada269')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cf3ce70-a8d7-4879-93ee-df95bbada269 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cf3ce70-a8d7-4879-93ee-df95bbada269');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "knn = KNNImputer(n_neighbors=3,weights='distance')\n",
        "\n",
        "knn.fit_transform(df.iloc[:,1:])[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEJiQ2tHbQm",
        "outputId": "a8a7fb59-18a0-4533-be91-996ea71a5ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.43000000e+06, 1.14611478e+05, 1.96000000e+05, 1.19000000e+03,\n",
              "       1.92000000e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['subs'].fillna(60580,inplace=True)"
      ],
      "metadata": {
        "id": "2lfQkYn5HjYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aMxbneqqHwSd",
        "outputId": "e3ae4b26-70b0-4b15-d933-3f1562f6648d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name        views       subs  last 30 days views  \\\n",
              "0                 Data School    9730000.0   193000.0            106000.0   \n",
              "1               Bhavesh Bhatt    2720000.0    37400.0             72700.0   \n",
              "2         Unfold Data Science    1720000.0    27900.0            123000.0   \n",
              "3             Abhishek Thakur    1740000.0    69800.0             59600.0   \n",
              "4                   AppliedAI   13200000.0    77900.0             98600.0   \n",
              "5       5 minutes engineering   37900000.0   303000.0           1610000.0   \n",
              "6             Serrano Academy    4770000.0    96400.0             70200.0   \n",
              "7                  Krish Naik   51100000.0   556000.0           1650000.0   \n",
              "8                  Codebasics   35000000.0   557000.0           1470000.0   \n",
              "9                   Statquest   35900000.0   702000.0           1390000.0   \n",
              "10                    CampusX    1500000.0    18000.0            198000.0   \n",
              "11          Satyajit Pattnaik     480000.0    19400.0             56400.0   \n",
              "12              Daniel Bourke    5280000.0   112000.0             84900.0   \n",
              "13                 Deeplizard    9330000.0   117000.0            167000.0   \n",
              "14                    Ken Jee    6060000.0   195000.0            153000.0   \n",
              "15            Python Engineer    6960000.0   115000.0            823000.0   \n",
              "16                  KGPTalkie    4450000.0    39800.0             88800.0   \n",
              "17             AI Engineering    1950000.0    62200.0             61400.0   \n",
              "18            Nicolas Renotte    3440000.0    67900.0            312000.0   \n",
              "19                 Siddaharan    1020000.0    48600.0            118000.0   \n",
              "20       Indian AI Production    3530000.0    31900.0            119000.0   \n",
              "21          The AI University    1330000.0    24000.0             46200.0   \n",
              "22              Harshit Tyagi     180000.0     8030.0              5240.0   \n",
              "23           Developer Ashish     320000.0    16200.0             13300.0   \n",
              "24            Normalized Nerd    1300000.0    30600.0            117000.0   \n",
              "25               Smitha Kolan    1090000.0    37800.0             45400.0   \n",
              "26         Shashank Kalanithi    3260000.0    81900.0            202000.0   \n",
              "27              DigitalSreeni    2570000.0    38400.0            198000.0   \n",
              "28             Brandon Rohrer    4390000.0    77300.0             46500.0   \n",
              "29                  Ranji Raj    6210000.0    42300.0            116000.0   \n",
              "30          Abhishek Agarrwal    7430000.0    60580.0            196000.0   \n",
              "31            Deeplearning.ai   11300000.0   170000.0            181000.0   \n",
              "32     Deep Learning in Hindi     330000.0     4470.0              8410.0   \n",
              "33              Fahad Hussain    1310000.0    16100.0             46500.0   \n",
              "34           Data Science Jay     970000.0    22400.0             66600.0   \n",
              "35              Sundas Khalid    2150000.0    64700.0            174000.0   \n",
              "36           Seattle Data Guy    1200000.0    26000.0            108000.0   \n",
              "37             Data Professor    2790000.0   116000.0            130000.0   \n",
              "38                 Tina Huang   10800000.0   294000.0            651000.0   \n",
              "39  Data Science Career Coach    1540000.0    28000.0            124000.0   \n",
              "40                    Sentdex  101000000.0  1110000.0            588000.0   \n",
              "41          Data Science Dojo    4690000.0    82700.0             66500.0   \n",
              "42     Data Science Tutorials    3890000.0    38100.0            130000.0   \n",
              "43              Brandon Foltz   23200000.0   262000.0            179000.0   \n",
              "44                   Datacamp   20800000.0   129000.0            627000.0   \n",
              "45               The Semiclon    2170000.0    23500.0             20300.0   \n",
              "46                 Ritvikmath    5780000.0    79900.0            215000.0   \n",
              "47                     kaggle    2940000.0   103000.0             55600.0   \n",
              "48                    ineuron    1130000.0    41700.0            705000.0   \n",
              "49                Springboard    3900000.0    53000.0            141000.0   \n",
              "50                     Jovian     950000.0    27000.0             59700.0   \n",
              "\n",
              "    num videos   old  \n",
              "0          138  2945  \n",
              "1          292  1509  \n",
              "2          369  1085  \n",
              "3          139   764  \n",
              "4          497  1583  \n",
              "5         1390  1260  \n",
              "6           43  1967  \n",
              "7         1360  1525  \n",
              "8          493  2231  \n",
              "9          217  2524  \n",
              "10        1100   859  \n",
              "11         305   582  \n",
              "12         291  1149  \n",
              "13         307  1531  \n",
              "14         230  1531  \n",
              "15         163   978  \n",
              "16         593  1352  \n",
              "17         261   903  \n",
              "18         181  1094  \n",
              "19         138   369  \n",
              "20         342  1118  \n",
              "21         332  1096  \n",
              "22          44   676  \n",
              "23          39   603  \n",
              "24          88   818  \n",
              "25          66   866  \n",
              "26         111   602  \n",
              "27         316   968  \n",
              "28         145  2076  \n",
              "29         539  2044  \n",
              "30        1190  1920  \n",
              "31         219  1616  \n",
              "32         201   943  \n",
              "33         741   923  \n",
              "34          95   731  \n",
              "35          51   525  \n",
              "36         122  1345  \n",
              "37         272   892  \n",
              "38          92   555  \n",
              "39        1410  1103  \n",
              "40        1250  3178  \n",
              "41         297  1672  \n",
              "42         869  1950  \n",
              "43         259  3468  \n",
              "44        1240  2483  \n",
              "45          46  1835  \n",
              "46         415  2504  \n",
              "47         346  1413  \n",
              "48         193   576  \n",
              "49         108  1009  \n",
              "50         148   813  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5dee055-aef8-46ac-999d-91b35d9ea190\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views</th>\n",
              "      <th>subs</th>\n",
              "      <th>last 30 days views</th>\n",
              "      <th>num videos</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>9730000.0</td>\n",
              "      <td>193000.0</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>2945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>2720000.0</td>\n",
              "      <td>37400.0</td>\n",
              "      <td>72700.0</td>\n",
              "      <td>292</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>1720000.0</td>\n",
              "      <td>27900.0</td>\n",
              "      <td>123000.0</td>\n",
              "      <td>369</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>1740000.0</td>\n",
              "      <td>69800.0</td>\n",
              "      <td>59600.0</td>\n",
              "      <td>139</td>\n",
              "      <td>764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>13200000.0</td>\n",
              "      <td>77900.0</td>\n",
              "      <td>98600.0</td>\n",
              "      <td>497</td>\n",
              "      <td>1583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>37900000.0</td>\n",
              "      <td>303000.0</td>\n",
              "      <td>1610000.0</td>\n",
              "      <td>1390</td>\n",
              "      <td>1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>4770000.0</td>\n",
              "      <td>96400.0</td>\n",
              "      <td>70200.0</td>\n",
              "      <td>43</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>51100000.0</td>\n",
              "      <td>556000.0</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>1360</td>\n",
              "      <td>1525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>35000000.0</td>\n",
              "      <td>557000.0</td>\n",
              "      <td>1470000.0</td>\n",
              "      <td>493</td>\n",
              "      <td>2231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>35900000.0</td>\n",
              "      <td>702000.0</td>\n",
              "      <td>1390000.0</td>\n",
              "      <td>217</td>\n",
              "      <td>2524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>1100</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>480000.0</td>\n",
              "      <td>19400.0</td>\n",
              "      <td>56400.0</td>\n",
              "      <td>305</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>5280000.0</td>\n",
              "      <td>112000.0</td>\n",
              "      <td>84900.0</td>\n",
              "      <td>291</td>\n",
              "      <td>1149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>9330000.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>167000.0</td>\n",
              "      <td>307</td>\n",
              "      <td>1531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>6060000.0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>153000.0</td>\n",
              "      <td>230</td>\n",
              "      <td>1531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>6960000.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>823000.0</td>\n",
              "      <td>163</td>\n",
              "      <td>978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>4450000.0</td>\n",
              "      <td>39800.0</td>\n",
              "      <td>88800.0</td>\n",
              "      <td>593</td>\n",
              "      <td>1352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>1950000.0</td>\n",
              "      <td>62200.0</td>\n",
              "      <td>61400.0</td>\n",
              "      <td>261</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>3440000.0</td>\n",
              "      <td>67900.0</td>\n",
              "      <td>312000.0</td>\n",
              "      <td>181</td>\n",
              "      <td>1094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>1020000.0</td>\n",
              "      <td>48600.0</td>\n",
              "      <td>118000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>3530000.0</td>\n",
              "      <td>31900.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>342</td>\n",
              "      <td>1118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>1330000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>46200.0</td>\n",
              "      <td>332</td>\n",
              "      <td>1096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>8030.0</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>44</td>\n",
              "      <td>676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>320000.0</td>\n",
              "      <td>16200.0</td>\n",
              "      <td>13300.0</td>\n",
              "      <td>39</td>\n",
              "      <td>603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>1300000.0</td>\n",
              "      <td>30600.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>88</td>\n",
              "      <td>818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>1090000.0</td>\n",
              "      <td>37800.0</td>\n",
              "      <td>45400.0</td>\n",
              "      <td>66</td>\n",
              "      <td>866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>3260000.0</td>\n",
              "      <td>81900.0</td>\n",
              "      <td>202000.0</td>\n",
              "      <td>111</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>2570000.0</td>\n",
              "      <td>38400.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>316</td>\n",
              "      <td>968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>4390000.0</td>\n",
              "      <td>77300.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>145</td>\n",
              "      <td>2076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>6210000.0</td>\n",
              "      <td>42300.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>539</td>\n",
              "      <td>2044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>7430000.0</td>\n",
              "      <td>60580.0</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1190</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>11300000.0</td>\n",
              "      <td>170000.0</td>\n",
              "      <td>181000.0</td>\n",
              "      <td>219</td>\n",
              "      <td>1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>330000.0</td>\n",
              "      <td>4470.0</td>\n",
              "      <td>8410.0</td>\n",
              "      <td>201</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>1310000.0</td>\n",
              "      <td>16100.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>741</td>\n",
              "      <td>923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>970000.0</td>\n",
              "      <td>22400.0</td>\n",
              "      <td>66600.0</td>\n",
              "      <td>95</td>\n",
              "      <td>731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>2150000.0</td>\n",
              "      <td>64700.0</td>\n",
              "      <td>174000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>1200000.0</td>\n",
              "      <td>26000.0</td>\n",
              "      <td>108000.0</td>\n",
              "      <td>122</td>\n",
              "      <td>1345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>2790000.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>272</td>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>10800000.0</td>\n",
              "      <td>294000.0</td>\n",
              "      <td>651000.0</td>\n",
              "      <td>92</td>\n",
              "      <td>555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1540000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>124000.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>101000000.0</td>\n",
              "      <td>1110000.0</td>\n",
              "      <td>588000.0</td>\n",
              "      <td>1250</td>\n",
              "      <td>3178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>4690000.0</td>\n",
              "      <td>82700.0</td>\n",
              "      <td>66500.0</td>\n",
              "      <td>297</td>\n",
              "      <td>1672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>3890000.0</td>\n",
              "      <td>38100.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>869</td>\n",
              "      <td>1950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>23200000.0</td>\n",
              "      <td>262000.0</td>\n",
              "      <td>179000.0</td>\n",
              "      <td>259</td>\n",
              "      <td>3468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>20800000.0</td>\n",
              "      <td>129000.0</td>\n",
              "      <td>627000.0</td>\n",
              "      <td>1240</td>\n",
              "      <td>2483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>2170000.0</td>\n",
              "      <td>23500.0</td>\n",
              "      <td>20300.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>5780000.0</td>\n",
              "      <td>79900.0</td>\n",
              "      <td>215000.0</td>\n",
              "      <td>415</td>\n",
              "      <td>2504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>2940000.0</td>\n",
              "      <td>103000.0</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>346</td>\n",
              "      <td>1413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>1130000.0</td>\n",
              "      <td>41700.0</td>\n",
              "      <td>705000.0</td>\n",
              "      <td>193</td>\n",
              "      <td>576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>3900000.0</td>\n",
              "      <td>53000.0</td>\n",
              "      <td>141000.0</td>\n",
              "      <td>108</td>\n",
              "      <td>1009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>950000.0</td>\n",
              "      <td>27000.0</td>\n",
              "      <td>59700.0</td>\n",
              "      <td>148</td>\n",
              "      <td>813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5dee055-aef8-46ac-999d-91b35d9ea190')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5dee055-aef8-46ac-999d-91b35d9ea190 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5dee055-aef8-46ac-999d-91b35d9ea190');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Views rank\n",
        "print(np.where(df.sort_values('views',ascending=False)['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJz10OLsIktG",
        "outputId": "91f1c6c0-bcce-44ba-d007-f614dd7e2b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 out of  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('views',ascending=False)[['channel name','views']].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZRTcHpiAJS_Z",
        "outputId": "0e9283f0-51e0-4711-ad8f-f24f7f10f0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             channel name        views\n",
              "40                Sentdex  101000000.0\n",
              "7              Krish Naik   51100000.0\n",
              "5   5 minutes engineering   37900000.0\n",
              "9               Statquest   35900000.0\n",
              "8              Codebasics   35000000.0\n",
              "43          Brandon Foltz   23200000.0\n",
              "44               Datacamp   20800000.0\n",
              "4               AppliedAI   13200000.0\n",
              "31        Deeplearning.ai   11300000.0\n",
              "38             Tina Huang   10800000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4f962c3-758c-4f7f-954f-15ecabdceb85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>101000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>51100000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>37900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>35900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>35000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>23200000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>20800000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>13200000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>11300000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>10800000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f962c3-758c-4f7f-954f-15ecabdceb85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4f962c3-758c-4f7f-954f-15ecabdceb85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4f962c3-758c-4f7f-954f-15ecabdceb85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subs rank\n",
        "print(np.where(df.sort_values('subs',ascending=False)['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72BCAF4VIp_d",
        "outputId": "5af82f64-b6ff-4ac7-bf7f-237526bfced9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 out of  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('subs',ascending=False)[['channel name','subs']].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ykg0ItR3J4Rw",
        "outputId": "04b47fc4-8fc6-4ee0-df23-c3bf8bb32696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             channel name       subs\n",
              "40                Sentdex  1110000.0\n",
              "9               Statquest   702000.0\n",
              "8              Codebasics   557000.0\n",
              "7              Krish Naik   556000.0\n",
              "5   5 minutes engineering   303000.0\n",
              "38             Tina Huang   294000.0\n",
              "43          Brandon Foltz   262000.0\n",
              "14                Ken Jee   195000.0\n",
              "0             Data School   193000.0\n",
              "31        Deeplearning.ai   170000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b49ce038-a9ce-464a-9850-bb84d6d6e105\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>subs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>1110000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>702000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>557000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>556000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>303000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>294000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>262000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>195000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>193000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>170000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b49ce038-a9ce-464a-9850-bb84d6d6e105')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b49ce038-a9ce-464a-9850-bb84d6d6e105 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b49ce038-a9ce-464a-9850-bb84d6d6e105');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of videos rank\n",
        "print(np.where(df.sort_values('num videos',ascending=False)['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ZlWF5AJFMd",
        "outputId": "7243f5b6-bcd3-4084-d8c9-e6cd4efa0296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 out of  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('num videos',ascending=False)[['channel name','num videos']].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nVLLkOUdJPYX",
        "outputId": "13521bb7-1e83-4058-b725-80d5751a7e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name  num videos\n",
              "39  Data Science Career Coach        1410\n",
              "5       5 minutes engineering        1390\n",
              "7                  Krish Naik        1360\n",
              "40                    Sentdex        1250\n",
              "44                   Datacamp        1240\n",
              "30          Abhishek Agarrwal        1190\n",
              "10                    CampusX        1100\n",
              "42     Data Science Tutorials         869\n",
              "33              Fahad Hussain         741\n",
              "16                  KGPTalkie         593"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80bae375-d9ef-410b-b3ca-9805397d6d9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>num videos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>1390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>1360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>1240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>1190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bae375-d9ef-410b-b3ca-9805397d6d9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80bae375-d9ef-410b-b3ca-9805397d6d9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80bae375-d9ef-410b-b3ca-9805397d6d9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How old\n",
        "print(np.where(df.sort_values('old',ascending=False)['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRy5lR8FKHoS",
        "outputId": "45eac1b6-fe26-4da1-852c-314285e11ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38 out of  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "old_df = df.sort_values('old',ascending=False)[['channel name','old']].head(15)\n",
        "old_df['old'] = round(old_df['old']/365)\n",
        "old_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "EkMnMgBjKsSu",
        "outputId": "24acf336-5866-40da-c7f6-7a7c1113bcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              channel name   old\n",
              "43           Brandon Foltz  10.0\n",
              "40                 Sentdex   9.0\n",
              "0              Data School   8.0\n",
              "9                Statquest   7.0\n",
              "46              Ritvikmath   7.0\n",
              "44                Datacamp   7.0\n",
              "8               Codebasics   6.0\n",
              "28          Brandon Rohrer   6.0\n",
              "29               Ranji Raj   6.0\n",
              "6          Serrano Academy   5.0\n",
              "42  Data Science Tutorials   5.0\n",
              "30       Abhishek Agarrwal   5.0\n",
              "45            The Semiclon   5.0\n",
              "41       Data Science Dojo   5.0\n",
              "31         Deeplearning.ai   4.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a21cbf0c-8bb5-4cfb-ad60-b55f4cb47274\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a21cbf0c-8bb5-4cfb-ad60-b55f4cb47274')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a21cbf0c-8bb5-4cfb-ad60-b55f4cb47274 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a21cbf0c-8bb5-4cfb-ad60-b55f4cb47274');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last 30 days performance\n",
        "print(np.where(df.sort_values('last 30 days views',ascending=False)['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqhdwMaJKxBp",
        "outputId": "abfbf28d-a1a1-415f-8ac4-ceb2eb85f617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 out of  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('last 30 days views',ascending=False)[['channel name','last 30 days views']].head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "4swy0zFYLvFO",
        "outputId": "283c7774-6de0-41e3-ec91-3b19aef64ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             channel name  last 30 days views\n",
              "7              Krish Naik           1650000.0\n",
              "5   5 minutes engineering           1610000.0\n",
              "8              Codebasics           1470000.0\n",
              "9               Statquest           1390000.0\n",
              "15        Python Engineer            823000.0\n",
              "48                ineuron            705000.0\n",
              "38             Tina Huang            651000.0\n",
              "44               Datacamp            627000.0\n",
              "40                Sentdex            588000.0\n",
              "18        Nicolas Renotte            312000.0\n",
              "46             Ritvikmath            215000.0\n",
              "26     Shashank Kalanithi            202000.0\n",
              "27          DigitalSreeni            198000.0\n",
              "10                CampusX            198000.0\n",
              "30      Abhishek Agarrwal            196000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30ceeeae-63c8-4c06-bd55-ccda6ea706a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>last 30 days views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>1650000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>1610000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>1470000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>1390000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>823000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>705000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>651000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>627000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>588000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>312000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>215000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>202000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>198000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>198000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>196000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30ceeeae-63c8-4c06-bd55-ccda6ea706a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30ceeeae-63c8-4c06-bd55-ccda6ea706a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30ceeeae-63c8-4c06-bd55-ccda6ea706a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 subscriber ke liye views required\n",
        "# view/subscriber count\n",
        "df['v/s count'] = df['views']/df['subs']\n",
        "\n",
        "print(51 - np.where(df['channel name'] == 'CampusX')[0][0],'out of ',df.shape[0])\n",
        "\n",
        "df[['channel name','v/s count']].sort_values(['v/s count'],ascending=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zq6oGgNYL6F5",
        "outputId": "a0a23844-7a6f-41e6-9a44-bd68fb3884b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 out of  51\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name   v/s count\n",
              "23           Developer Ashish   19.753086\n",
              "19                 Siddaharan   20.987654\n",
              "22              Harshit Tyagi   22.415940\n",
              "37             Data Professor   24.051724\n",
              "11          Satyajit Pattnaik   24.742268\n",
              "3             Abhishek Thakur   24.928367\n",
              "48                    ineuron   27.098321\n",
              "47                     kaggle   28.543689\n",
              "25               Smitha Kolan   28.835979\n",
              "14                    Ken Jee   31.076923\n",
              "17             AI Engineering   31.350482\n",
              "35              Sundas Khalid   33.230294\n",
              "50                     Jovian   35.185185\n",
              "38                 Tina Huang   36.734694\n",
              "26         Shashank Kalanithi   39.804640\n",
              "24            Normalized Nerd   42.483660\n",
              "34           Data Science Jay   43.303571\n",
              "36           Seattle Data Guy   46.153846\n",
              "12              Daniel Bourke   47.142857\n",
              "6             Serrano Academy   49.481328\n",
              "0                 Data School   50.414508\n",
              "18            Nicolas Renotte   50.662739\n",
              "9                   Statquest   51.139601\n",
              "39  Data Science Career Coach   55.000000\n",
              "21          The AI University   55.416667\n",
              "41          Data Science Dojo   56.711004\n",
              "28             Brandon Rohrer   56.791721\n",
              "15            Python Engineer   60.521739\n",
              "2         Unfold Data Science   61.648746\n",
              "8                  Codebasics   62.836625\n",
              "31            Deeplearning.ai   66.470588\n",
              "27              DigitalSreeni   66.927083\n",
              "46                 Ritvikmath   72.340426\n",
              "1               Bhavesh Bhatt   72.727273\n",
              "49                Springboard   73.584906\n",
              "32     Deep Learning in Hindi   73.825503\n",
              "13                 Deeplizard   79.743590\n",
              "33              Fahad Hussain   81.366460\n",
              "10                    CampusX   83.333333\n",
              "43              Brandon Foltz   88.549618\n",
              "40                    Sentdex   90.990991\n",
              "7                  Krish Naik   91.906475\n",
              "45               The Semiclon   92.340426\n",
              "42     Data Science Tutorials  102.099738\n",
              "20       Indian AI Production  110.658307\n",
              "16                  KGPTalkie  111.809045\n",
              "30          Abhishek Agarrwal  122.647739\n",
              "5       5 minutes engineering  125.082508\n",
              "29                  Ranji Raj  146.808511\n",
              "44                   Datacamp  161.240310\n",
              "4                   AppliedAI  169.448010"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fee9d385-2c28-4af1-b6e8-3373352b3299\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>v/s count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>19.753086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>20.987654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>22.415940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>24.051724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>24.742268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>24.928367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>27.098321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>28.543689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>28.835979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>31.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>31.350482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>33.230294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>35.185185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>36.734694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>39.804640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>42.483660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>43.303571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>46.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>47.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>49.481328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>50.414508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>50.662739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>51.139601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>55.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>56.711004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>56.791721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>60.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>61.648746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>62.836625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>66.470588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>66.927083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>72.340426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>72.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>73.584906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>73.825503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>79.743590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>81.366460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>83.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>88.549618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>90.990991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>91.906475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>92.340426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>102.099738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>110.658307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>111.809045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>122.647739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>125.082508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>146.808511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>161.240310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>169.448010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fee9d385-2c28-4af1-b6e8-3373352b3299')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fee9d385-2c28-4af1-b6e8-3373352b3299 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fee9d385-2c28-4af1-b6e8-3373352b3299');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(data_frame=df,x=df['views'], y=df['subs'],hover_name=df['channel name'])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "kTXLmPqoPGi2",
        "outputId": "7a18760c-5aa4-4dc1-f553-c76ab39c4f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"145db6cb-313e-4d23-a7e9-a06f39e04fde\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"145db6cb-313e-4d23-a7e9-a06f39e04fde\")) {                    Plotly.newPlot(                        \"145db6cb-313e-4d23-a7e9-a06f39e04fde\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>views=%{x}<br>subs=%{y}<extra></extra>\",\"hovertext\":[\"Data School\",\"Bhavesh Bhatt\",\"Unfold Data Science\",\"Abhishek Thakur\",\"AppliedAI\",\"5 minutes engineering\",\"Serrano Academy\",\"Krish Naik\",\"Codebasics\",\"Statquest\",\"CampusX\",\"Satyajit Pattnaik\",\"Daniel Bourke\",\"Deeplizard\",\"Ken Jee\",\"Python Engineer\",\"KGPTalkie\",\"AI Engineering\",\"Nicolas Renotte\",\"Siddaharan\",\"Indian AI Production\",\"The AI University\",\"Harshit Tyagi\",\"Developer Ashish\",\"Normalized Nerd\",\"Smitha Kolan\",\"Shashank Kalanithi\",\"DigitalSreeni\",\"Brandon Rohrer\",\"Ranji Raj\",\"Abhishek Agarrwal\",\"Deeplearning.ai\",\"Deep Learning in Hindi\",\"Fahad Hussain\",\"Data Science Jay\",\"Sundas Khalid\",\"Seattle Data Guy\",\"Data Professor\",\"Tina Huang\",\"Data Science Career Coach\",\"Sentdex\",\"Data Science Dojo\",\"Data Science Tutorials\",\"Brandon Foltz\",\"Datacamp\",\"The Semiclon\",\"Ritvikmath\",\"kaggle\",\"ineuron\",\"Springboard\",\"Jovian\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[9730000.0,2720000.0,1720000.0,1740000.0,13200000.0,37900000.0,4770000.0,51100000.0,35000000.0,35900000.0,1500000.0,480000.0,5280000.0,9330000.0,6060000.0,6960000.0,4450000.0,1950000.0,3440000.0,1020000.0,3530000.0,1330000.0,180000.0,320000.0,1300000.0,1090000.0,3260000.0,2570000.0,4390000.0,6210000.0,7430000.0,11300000.0,330000.0,1310000.0,970000.0,2150000.0,1200000.0,2790000.0,10800000.0,1540000.0,101000000.0,4690000.0,3890000.0,23200000.0,20800000.0,2170000.0,5780000.0,2940000.0,1130000.0,3900000.0,950000.0],\"xaxis\":\"x\",\"y\":[193000.0,37400.0,27900.0,69800.0,77900.0,303000.0,96400.0,556000.0,557000.0,702000.0,18000.0,19400.0,112000.0,117000.0,195000.0,115000.0,39800.0,62200.0,67900.0,48600.0,31900.0,24000.0,8029.999999999999,16200.0,30600.0,37800.0,81900.0,38400.0,77300.0,42300.0,60580.0,170000.0,4470.0,16100.000000000002,22400.0,64700.0,26000.0,116000.0,294000.0,28000.0,1110000.0,82700.0,38100.0,262000.0,129000.0,23500.0,79900.0,103000.0,41700.0,53000.0,27000.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"views\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"subs\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('145db6cb-313e-4d23-a7e9-a06f39e04fde');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = df[df['views']>=1000000]\n",
        "fig = px.scatter(data_frame=temp_df,x=temp_df['views'], y=temp_df['subs'],hover_name=temp_df['channel name'])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "BDNEPtFnPsiy",
        "outputId": "35e29a02-f037-47c4-bc4d-3b845bb12e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"077a266d-3a28-4150-aaca-45d0999fe69d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"077a266d-3a28-4150-aaca-45d0999fe69d\")) {                    Plotly.newPlot(                        \"077a266d-3a28-4150-aaca-45d0999fe69d\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>views=%{x}<br>subs=%{y}<extra></extra>\",\"hovertext\":[\"Data School\",\"Bhavesh Bhatt\",\"Unfold Data Science\",\"Abhishek Thakur\",\"AppliedAI\",\"5 minutes engineering\",\"Serrano Academy\",\"Krish Naik\",\"Codebasics\",\"Statquest\",\"CampusX\",\"Daniel Bourke\",\"Deeplizard\",\"Ken Jee\",\"Python Engineer\",\"KGPTalkie\",\"AI Engineering\",\"Nicolas Renotte\",\"Siddaharan\",\"Indian AI Production\",\"The AI University\",\"Normalized Nerd\",\"Smitha Kolan\",\"Shashank Kalanithi\",\"DigitalSreeni\",\"Brandon Rohrer\",\"Ranji Raj\",\"Abhishek Agarrwal\",\"Deeplearning.ai\",\"Fahad Hussain\",\"Sundas Khalid\",\"Seattle Data Guy\",\"Data Professor\",\"Tina Huang\",\"Data Science Career Coach\",\"Sentdex\",\"Data Science Dojo\",\"Data Science Tutorials\",\"Brandon Foltz\",\"Datacamp\",\"The Semiclon\",\"Ritvikmath\",\"kaggle\",\"ineuron\",\"Springboard\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[9730000.0,2720000.0,1720000.0,1740000.0,13200000.0,37900000.0,4770000.0,51100000.0,35000000.0,35900000.0,1500000.0,5280000.0,9330000.0,6060000.0,6960000.0,4450000.0,1950000.0,3440000.0,1020000.0,3530000.0,1330000.0,1300000.0,1090000.0,3260000.0,2570000.0,4390000.0,6210000.0,7430000.0,11300000.0,1310000.0,2150000.0,1200000.0,2790000.0,10800000.0,1540000.0,101000000.0,4690000.0,3890000.0,23200000.0,20800000.0,2170000.0,5780000.0,2940000.0,1130000.0,3900000.0],\"xaxis\":\"x\",\"y\":[193000.0,37400.0,27900.0,69800.0,77900.0,303000.0,96400.0,556000.0,557000.0,702000.0,18000.0,112000.0,117000.0,195000.0,115000.0,39800.0,62200.0,67900.0,48600.0,31900.0,24000.0,30600.0,37800.0,81900.0,38400.0,77300.0,42300.0,60580.0,170000.0,16100.000000000002,64700.0,26000.0,116000.0,294000.0,28000.0,1110000.0,82700.0,38100.0,262000.0,129000.0,23500.0,79900.0,103000.0,41700.0,53000.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"views\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"subs\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('077a266d-3a28-4150-aaca-45d0999fe69d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# videos/subs ratio\n",
        "df['vids/subs count'] = df['num videos']/df['subs']\n",
        "df[['channel name','vids/subs count']].sort_values(['vids/subs count'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vp2D0aO8R236",
        "outputId": "832a2f58-8913-4fe8-dd05-7cd624763684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name  vids/subs count\n",
              "9                   Statquest         0.000309\n",
              "38                 Tina Huang         0.000313\n",
              "6             Serrano Academy         0.000446\n",
              "0                 Data School         0.000715\n",
              "35              Sundas Khalid         0.000788\n",
              "8                  Codebasics         0.000885\n",
              "43              Brandon Foltz         0.000989\n",
              "40                    Sentdex         0.001126\n",
              "14                    Ken Jee         0.001179\n",
              "31            Deeplearning.ai         0.001288\n",
              "26         Shashank Kalanithi         0.001355\n",
              "15            Python Engineer         0.001417\n",
              "25               Smitha Kolan         0.001746\n",
              "28             Brandon Rohrer         0.001876\n",
              "45               The Semiclon         0.001957\n",
              "3             Abhishek Thakur         0.001991\n",
              "49                Springboard         0.002038\n",
              "37             Data Professor         0.002345\n",
              "23           Developer Ashish         0.002407\n",
              "7                  Krish Naik         0.002446\n",
              "12              Daniel Bourke         0.002598\n",
              "13                 Deeplizard         0.002624\n",
              "18            Nicolas Renotte         0.002666\n",
              "19                 Siddaharan         0.002840\n",
              "24            Normalized Nerd         0.002876\n",
              "47                     kaggle         0.003359\n",
              "41          Data Science Dojo         0.003591\n",
              "17             AI Engineering         0.004196\n",
              "34           Data Science Jay         0.004241\n",
              "5       5 minutes engineering         0.004587\n",
              "48                    ineuron         0.004628\n",
              "36           Seattle Data Guy         0.004692\n",
              "46                 Ritvikmath         0.005194\n",
              "22              Harshit Tyagi         0.005479\n",
              "50                     Jovian         0.005481\n",
              "4                   AppliedAI         0.006380\n",
              "1               Bhavesh Bhatt         0.007807\n",
              "27              DigitalSreeni         0.008229\n",
              "44                   Datacamp         0.009612\n",
              "20       Indian AI Production         0.010721\n",
              "29                  Ranji Raj         0.012742\n",
              "2         Unfold Data Science         0.013226\n",
              "21          The AI University         0.013833\n",
              "16                  KGPTalkie         0.014899\n",
              "11          Satyajit Pattnaik         0.015722\n",
              "30          Abhishek Agarrwal         0.019643\n",
              "42     Data Science Tutorials         0.022808\n",
              "32     Deep Learning in Hindi         0.044966\n",
              "33              Fahad Hussain         0.046025\n",
              "39  Data Science Career Coach         0.050357\n",
              "10                    CampusX         0.061111"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8416ffa2-1e11-438a-a674-54732467e4cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>vids/subs count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>0.000309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>0.000313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>0.000446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>0.000715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>0.000788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>0.000885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>0.000989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>0.001126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>0.001179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>0.001288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>0.001355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>0.001417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>0.001746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>0.001876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>0.001957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>0.001991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>0.002038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>0.002345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>0.002407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>0.002446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>0.002598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>0.002624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>0.002666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>0.002840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>0.002876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>0.003359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>0.003591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>0.004196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>0.004241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>0.004587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>0.004628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>0.004692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>0.005194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>0.005481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>0.006380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>0.007807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>0.008229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>0.009612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>0.010721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>0.012742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>0.013226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>0.013833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>0.014899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>0.015722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>0.019643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>0.022808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>0.044966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>0.046025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>0.050357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>0.061111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8416ffa2-1e11-438a-a674-54732467e4cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8416ffa2-1e11-438a-a674-54732467e4cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8416ffa2-1e11-438a-a674-54732467e4cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# per day sub gain(time required to gain 1 subscriber)\n",
        "df['per_day_subs_gain'] = df['old']/df['subs']\n",
        "temp_df = df[['channel name','per_day_subs_gain']].sort_values(['per_day_subs_gain'])\n",
        "temp_df['per_day_subs_gain'] = temp_df['per_day_subs_gain']*24*60\n",
        "\n",
        "print(np.where(temp_df['channel name'] == 'CampusX')[0][0],'out of ',temp_df.shape[0])\n",
        "\n",
        "temp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "prNGR0TpSMty",
        "outputId": "8f4cb372-c187-41bd-d27e-d00a0b4ad04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 out of  51\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name  per_day_subs_gain\n",
              "38                 Tina Huang           2.718367\n",
              "7                  Krish Naik           3.949640\n",
              "40                    Sentdex           4.122811\n",
              "9                   Statquest           5.177436\n",
              "8                  Codebasics           5.767756\n",
              "5       5 minutes engineering           5.988119\n",
              "26         Shashank Kalanithi          10.584615\n",
              "19                 Siddaharan          10.933333\n",
              "37             Data Professor          11.073103\n",
              "14                    Ken Jee          11.305846\n",
              "35              Sundas Khalid          11.684699\n",
              "15            Python Engineer          12.246261\n",
              "31            Deeplearning.ai          13.688471\n",
              "12              Daniel Bourke          14.772857\n",
              "3             Abhishek Thakur          15.761605\n",
              "13                 Deeplizard          18.843077\n",
              "43              Brandon Foltz          19.060763\n",
              "47                     kaggle          19.754563\n",
              "48                    ineuron          19.890647\n",
              "17             AI Engineering          20.905466\n",
              "0                 Data School          21.973057\n",
              "18            Nicolas Renotte          23.201178\n",
              "49                Springboard          27.414340\n",
              "44                   Datacamp          27.717209\n",
              "41          Data Science Dojo          29.113422\n",
              "4                   AppliedAI          29.262131\n",
              "6             Serrano Academy          29.382573\n",
              "25               Smitha Kolan          32.990476\n",
              "27              DigitalSreeni          36.300000\n",
              "24            Normalized Nerd          38.494118\n",
              "28             Brandon Rohrer          38.673221\n",
              "11          Satyajit Pattnaik          43.200000\n",
              "50                     Jovian          43.360000\n",
              "46                 Ritvikmath          45.128411\n",
              "30          Abhishek Agarrwal          45.638825\n",
              "34           Data Science Jay          46.992857\n",
              "16                  KGPTalkie          48.916583\n",
              "20       Indian AI Production          50.467712\n",
              "23           Developer Ashish          53.600000\n",
              "2         Unfold Data Science          56.000000\n",
              "39  Data Science Career Coach          56.725714\n",
              "1               Bhavesh Bhatt          58.100535\n",
              "21          The AI University          65.760000\n",
              "10                    CampusX          68.720000\n",
              "29                  Ranji Raj          69.582979\n",
              "42     Data Science Tutorials          73.700787\n",
              "36           Seattle Data Guy          74.492308\n",
              "33              Fahad Hussain          82.554037\n",
              "45               The Semiclon         112.442553\n",
              "22              Harshit Tyagi         121.225405\n",
              "32     Deep Learning in Hindi         303.785235"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df6228b4-fd5f-4545-89c8-ef8d1f764d82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>per_day_subs_gain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>2.718367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>3.949640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>4.122811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>5.177436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>5.767756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>5.988119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>10.584615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>10.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>11.073103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>11.305846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>11.684699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>12.246261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>13.688471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>14.772857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>15.761605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>18.843077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>19.060763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>19.754563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>19.890647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>20.905466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>21.973057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>23.201178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>27.414340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>27.717209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>29.113422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>29.262131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>29.382573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>32.990476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>36.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>38.494118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>38.673221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>43.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>43.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>45.128411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>45.638825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>46.992857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>48.916583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>50.467712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>53.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>56.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>56.725714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>58.100535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>65.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>68.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>69.582979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>73.700787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>74.492308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>82.554037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>112.442553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>121.225405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>303.785235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df6228b4-fd5f-4545-89c8-ef8d1f764d82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df6228b4-fd5f-4545-89c8-ef8d1f764d82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df6228b4-fd5f-4545-89c8-ef8d1f764d82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aukaad ratio(how many views per subscriber provides)\n",
        "df['last_month_subs_ratio'] = df['last 30 days views']/df['subs']\n",
        "df[['channel name','last_month_subs_ratio']].sort_values(['last_month_subs_ratio'],ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0f1o7ihvSjMe",
        "outputId": "f39dc9ed-b1eb-4524-9c5a-c025c3218e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name  last_month_subs_ratio\n",
              "48                    ineuron              16.906475\n",
              "10                    CampusX              11.000000\n",
              "15            Python Engineer               7.156522\n",
              "5       5 minutes engineering               5.313531\n",
              "27              DigitalSreeni               5.156250\n",
              "44                   Datacamp               4.860465\n",
              "18            Nicolas Renotte               4.594993\n",
              "39  Data Science Career Coach               4.428571\n",
              "2         Unfold Data Science               4.408602\n",
              "36           Seattle Data Guy               4.153846\n",
              "24            Normalized Nerd               3.823529\n",
              "20       Indian AI Production               3.730408\n",
              "42     Data Science Tutorials               3.412073\n",
              "30          Abhishek Agarrwal               3.235391\n",
              "34           Data Science Jay               2.973214\n",
              "7                  Krish Naik               2.967626\n",
              "11          Satyajit Pattnaik               2.907216\n",
              "33              Fahad Hussain               2.888199\n",
              "29                  Ranji Raj               2.742317\n",
              "46                 Ritvikmath               2.690864\n",
              "35              Sundas Khalid               2.689335\n",
              "49                Springboard               2.660377\n",
              "8                  Codebasics               2.639138\n",
              "26         Shashank Kalanithi               2.466422\n",
              "19                 Siddaharan               2.427984\n",
              "16                  KGPTalkie               2.231156\n",
              "38                 Tina Huang               2.214286\n",
              "50                     Jovian               2.211111\n",
              "9                   Statquest               1.980057\n",
              "1               Bhavesh Bhatt               1.943850\n",
              "21          The AI University               1.925000\n",
              "32     Deep Learning in Hindi               1.881432\n",
              "13                 Deeplizard               1.427350\n",
              "4                   AppliedAI               1.265725\n",
              "25               Smitha Kolan               1.201058\n",
              "37             Data Professor               1.120690\n",
              "31            Deeplearning.ai               1.064706\n",
              "17             AI Engineering               0.987138\n",
              "45               The Semiclon               0.863830\n",
              "3             Abhishek Thakur               0.853868\n",
              "23           Developer Ashish               0.820988\n",
              "41          Data Science Dojo               0.804111\n",
              "14                    Ken Jee               0.784615\n",
              "12              Daniel Bourke               0.758036\n",
              "6             Serrano Academy               0.728216\n",
              "43              Brandon Foltz               0.683206\n",
              "22              Harshit Tyagi               0.652553\n",
              "28             Brandon Rohrer               0.601552\n",
              "0                 Data School               0.549223\n",
              "47                     kaggle               0.539806\n",
              "40                    Sentdex               0.529730"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ac85ef3-618d-4ed9-9b70-bae34cb46adb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>last_month_subs_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>16.906475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>7.156522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>5.313531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>5.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>4.860465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>4.594993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>4.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>4.408602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>4.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>3.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>3.730408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>3.412073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>3.235391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>2.973214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>2.967626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>2.907216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>2.888199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>2.742317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>2.690864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>2.689335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>2.660377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>2.639138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>2.466422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>2.427984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>2.231156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>2.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>2.211111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>1.980057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>1.943850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>1.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>1.881432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>1.427350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>1.265725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>1.201058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>1.120690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>1.064706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>0.987138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>0.863830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>0.853868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>0.820988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>0.804111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>0.784615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>0.758036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>0.728216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>0.683206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>0.652553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>0.601552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>0.549223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>0.539806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>0.529730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ac85ef3-618d-4ed9-9b70-bae34cb46adb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ac85ef3-618d-4ed9-9b70-bae34cb46adb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ac85ef3-618d-4ed9-9b70-bae34cb46adb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# views/minute\n",
        "df['views/day'] = df['views']/df['old']\n",
        "temp_df = df[['channel name','views/day']].sort_values(['views/day'],ascending=False)\n",
        "\n",
        "print(np.where(temp_df['channel name'] == 'CampusX')[0][0],'out of ',temp_df.shape[0])\n",
        "\n",
        "temp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hDLgGLN_mEPW",
        "outputId": "cc52f1b8-1598-4706-de2b-2066901a2602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 out of  51\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name     views/day\n",
              "7                  Krish Naik  33508.196721\n",
              "40                    Sentdex  31780.994336\n",
              "5       5 minutes engineering  30079.365079\n",
              "38                 Tina Huang  19459.459459\n",
              "8                  Codebasics  15688.032273\n",
              "9                   Statquest  14223.454834\n",
              "44                   Datacamp   8376.963351\n",
              "4                   AppliedAI   8338.597599\n",
              "15            Python Engineer   7116.564417\n",
              "31            Deeplearning.ai   6992.574257\n",
              "43              Brandon Foltz   6689.734717\n",
              "13                 Deeplizard   6094.056172\n",
              "26         Shashank Kalanithi   5415.282392\n",
              "12              Daniel Bourke   4595.300261\n",
              "35              Sundas Khalid   4095.238095\n",
              "14                    Ken Jee   3958.197257\n",
              "30          Abhishek Agarrwal   3869.791667\n",
              "49                Springboard   3865.213082\n",
              "0                 Data School   3303.904924\n",
              "16                  KGPTalkie   3291.420118\n",
              "20       Indian AI Production   3157.423971\n",
              "18            Nicolas Renotte   3144.424132\n",
              "37             Data Professor   3127.802691\n",
              "29                  Ranji Raj   3038.160470\n",
              "41          Data Science Dojo   2805.023923\n",
              "19                 Siddaharan   2764.227642\n",
              "27              DigitalSreeni   2654.958678\n",
              "6             Serrano Academy   2425.012710\n",
              "46                 Ritvikmath   2308.306709\n",
              "3             Abhishek Thakur   2277.486911\n",
              "17             AI Engineering   2159.468439\n",
              "28             Brandon Rohrer   2114.643545\n",
              "47                     kaggle   2080.679406\n",
              "42     Data Science Tutorials   1994.871795\n",
              "48                    ineuron   1961.805556\n",
              "1               Bhavesh Bhatt   1802.518224\n",
              "10                    CampusX   1746.216531\n",
              "24            Normalized Nerd   1589.242054\n",
              "2         Unfold Data Science   1585.253456\n",
              "33              Fahad Hussain   1419.284940\n",
              "39  Data Science Career Coach   1396.192203\n",
              "34           Data Science Jay   1326.949384\n",
              "25               Smitha Kolan   1258.660508\n",
              "21          The AI University   1213.503650\n",
              "45               The Semiclon   1182.561308\n",
              "50                     Jovian   1168.511685\n",
              "36           Seattle Data Guy    892.193309\n",
              "11          Satyajit Pattnaik    824.742268\n",
              "23           Developer Ashish    530.679934\n",
              "32     Deep Learning in Hindi    349.946978\n",
              "22              Harshit Tyagi    266.272189"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-324c1c86-b269-4cb6-80d3-679490f0df33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views/day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>33508.196721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>31780.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>30079.365079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>19459.459459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>15688.032273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>14223.454834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>8376.963351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>8338.597599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>7116.564417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>6992.574257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>6689.734717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>6094.056172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>5415.282392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>4595.300261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>4095.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>3958.197257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>3869.791667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>3865.213082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>3303.904924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>3291.420118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>3157.423971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>3144.424132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>3127.802691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>3038.160470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>2805.023923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>2764.227642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>2654.958678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>2425.012710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>2308.306709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>2277.486911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>2159.468439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>2114.643545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>2080.679406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>1994.871795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>1961.805556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>1802.518224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1746.216531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>1589.242054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>1585.253456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>1419.284940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1396.192203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>1326.949384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>1258.660508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>1213.503650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>1182.561308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>1168.511685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>892.193309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>824.742268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>530.679934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>349.946978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>266.272189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-324c1c86-b269-4cb6-80d3-679490f0df33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-324c1c86-b269-4cb6-80d3-679490f0df33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-324c1c86-b269-4cb6-80d3-679490f0df33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# views/video\n",
        "df['views/num_video'] = df['views']/df['num videos']\n",
        "temp_df = df[['channel name','views/num_video']].sort_values(['views/num_video'],ascending=False)\n",
        "\n",
        "print(np.where(temp_df['channel name'] == 'CampusX')[0][0],'out of ',temp_df.shape[0])\n",
        "\n",
        "temp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6qSi8ffGmvd-",
        "outputId": "c6963a44-aad8-4260-d07c-1a0a87c8e859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 out of  51\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 channel name  views/num_video\n",
              "9                   Statquest    165437.788018\n",
              "38                 Tina Huang    117391.304348\n",
              "6             Serrano Academy    110930.232558\n",
              "43              Brandon Foltz     89575.289575\n",
              "40                    Sentdex     80800.000000\n",
              "8                  Codebasics     70993.914807\n",
              "0                 Data School     70507.246377\n",
              "31            Deeplearning.ai     51598.173516\n",
              "45               The Semiclon     47173.913043\n",
              "15            Python Engineer     42699.386503\n",
              "35              Sundas Khalid     42156.862745\n",
              "7                  Krish Naik     37573.529412\n",
              "49                Springboard     36111.111111\n",
              "13                 Deeplizard     30390.879479\n",
              "28             Brandon Rohrer     30275.862069\n",
              "26         Shashank Kalanithi     29369.369369\n",
              "5       5 minutes engineering     27266.187050\n",
              "4                   AppliedAI     26559.356137\n",
              "14                    Ken Jee     26347.826087\n",
              "18            Nicolas Renotte     19005.524862\n",
              "12              Daniel Bourke     18144.329897\n",
              "44                   Datacamp     16774.193548\n",
              "25               Smitha Kolan     16515.151515\n",
              "41          Data Science Dojo     15791.245791\n",
              "24            Normalized Nerd     14772.727273\n",
              "46                 Ritvikmath     13927.710843\n",
              "3             Abhishek Thakur     12517.985612\n",
              "29                  Ranji Raj     11521.335807\n",
              "20       Indian AI Production     10321.637427\n",
              "37             Data Professor     10257.352941\n",
              "34           Data Science Jay     10210.526316\n",
              "36           Seattle Data Guy      9836.065574\n",
              "1               Bhavesh Bhatt      9315.068493\n",
              "47                     kaggle      8497.109827\n",
              "23           Developer Ashish      8205.128205\n",
              "27              DigitalSreeni      8132.911392\n",
              "16                  KGPTalkie      7504.215852\n",
              "17             AI Engineering      7471.264368\n",
              "19                 Siddaharan      7391.304348\n",
              "50                     Jovian      6418.918919\n",
              "30          Abhishek Agarrwal      6243.697479\n",
              "48                    ineuron      5854.922280\n",
              "2         Unfold Data Science      4661.246612\n",
              "42     Data Science Tutorials      4476.409666\n",
              "22              Harshit Tyagi      4090.909091\n",
              "21          The AI University      4006.024096\n",
              "33              Fahad Hussain      1767.881242\n",
              "32     Deep Learning in Hindi      1641.791045\n",
              "11          Satyajit Pattnaik      1573.770492\n",
              "10                    CampusX      1363.636364\n",
              "39  Data Science Career Coach      1092.198582"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d1c28df-1844-445d-b956-b55d75dc2756\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel name</th>\n",
              "      <th>views/num_video</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Statquest</td>\n",
              "      <td>165437.788018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Tina Huang</td>\n",
              "      <td>117391.304348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Serrano Academy</td>\n",
              "      <td>110930.232558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Brandon Foltz</td>\n",
              "      <td>89575.289575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Sentdex</td>\n",
              "      <td>80800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Codebasics</td>\n",
              "      <td>70993.914807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data School</td>\n",
              "      <td>70507.246377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Deeplearning.ai</td>\n",
              "      <td>51598.173516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>The Semiclon</td>\n",
              "      <td>47173.913043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Python Engineer</td>\n",
              "      <td>42699.386503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Sundas Khalid</td>\n",
              "      <td>42156.862745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Krish Naik</td>\n",
              "      <td>37573.529412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Springboard</td>\n",
              "      <td>36111.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Deeplizard</td>\n",
              "      <td>30390.879479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brandon Rohrer</td>\n",
              "      <td>30275.862069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Shashank Kalanithi</td>\n",
              "      <td>29369.369369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5 minutes engineering</td>\n",
              "      <td>27266.187050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AppliedAI</td>\n",
              "      <td>26559.356137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ken Jee</td>\n",
              "      <td>26347.826087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nicolas Renotte</td>\n",
              "      <td>19005.524862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Daniel Bourke</td>\n",
              "      <td>18144.329897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Datacamp</td>\n",
              "      <td>16774.193548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Smitha Kolan</td>\n",
              "      <td>16515.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Data Science Dojo</td>\n",
              "      <td>15791.245791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Normalized Nerd</td>\n",
              "      <td>14772.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Ritvikmath</td>\n",
              "      <td>13927.710843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abhishek Thakur</td>\n",
              "      <td>12517.985612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ranji Raj</td>\n",
              "      <td>11521.335807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Indian AI Production</td>\n",
              "      <td>10321.637427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Data Professor</td>\n",
              "      <td>10257.352941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Science Jay</td>\n",
              "      <td>10210.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Seattle Data Guy</td>\n",
              "      <td>9836.065574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bhavesh Bhatt</td>\n",
              "      <td>9315.068493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>kaggle</td>\n",
              "      <td>8497.109827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Developer Ashish</td>\n",
              "      <td>8205.128205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>DigitalSreeni</td>\n",
              "      <td>8132.911392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KGPTalkie</td>\n",
              "      <td>7504.215852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AI Engineering</td>\n",
              "      <td>7471.264368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Siddaharan</td>\n",
              "      <td>7391.304348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Jovian</td>\n",
              "      <td>6418.918919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Abhishek Agarrwal</td>\n",
              "      <td>6243.697479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ineuron</td>\n",
              "      <td>5854.922280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unfold Data Science</td>\n",
              "      <td>4661.246612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Data Science Tutorials</td>\n",
              "      <td>4476.409666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Harshit Tyagi</td>\n",
              "      <td>4090.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The AI University</td>\n",
              "      <td>4006.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fahad Hussain</td>\n",
              "      <td>1767.881242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Learning in Hindi</td>\n",
              "      <td>1641.791045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Satyajit Pattnaik</td>\n",
              "      <td>1573.770492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CampusX</td>\n",
              "      <td>1363.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Data Science Career Coach</td>\n",
              "      <td>1092.198582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d1c28df-1844-445d-b956-b55d75dc2756')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d1c28df-1844-445d-b956-b55d75dc2756 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d1c28df-1844-445d-b956-b55d75dc2756');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# pca(higher dim viz)\n",
        "viz_df = df[['channel name','views','subs','last 30 days views','num videos','old']]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = viz_df.iloc[:, 1:].values\n",
        "# Standardizing the features\n",
        "X = StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "hXU8dSwBUXWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_embedded = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "3nuUv2QaVyD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_embedded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdO7CJmTWcN2",
        "outputId": "779a2332-0523-4195-b46c-89c5b6d4e20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.75823835e-01, -2.16614667e+00],\n",
              "       [-6.81393623e-01, -4.22782904e-01],\n",
              "       [-8.31762958e-01,  1.74009762e-01],\n",
              "       [-1.15639844e+00,  1.58759485e-01],\n",
              "       [ 6.54233718e-03, -3.03082949e-01],\n",
              "       [ 3.60619789e+00,  2.60506639e+00],\n",
              "       [-4.53960167e-01, -1.21798196e+00],\n",
              "       [ 4.83883267e+00,  2.15508127e+00],\n",
              "       [ 3.72338637e+00,  3.05898757e-01],\n",
              "       [ 3.94967397e+00, -4.83376334e-01],\n",
              "       [-2.48318906e-01,  1.30667759e+00],\n",
              "       [-1.27607320e+00,  5.59907282e-01],\n",
              "       [-5.75427421e-01, -8.33597189e-02],\n",
              "       [-1.38577543e-01, -3.84169114e-01],\n",
              "       [-1.22303367e-01, -5.18265175e-01],\n",
              "       [ 6.16258344e-02,  8.28545936e-01],\n",
              "       [-4.14152485e-01,  8.31031233e-02],\n",
              "       [-9.88275968e-01,  1.52594576e-01],\n",
              "       [-6.36570596e-01,  1.55794730e-01],\n",
              "       [-1.37478156e+00,  6.55137417e-01],\n",
              "       [-7.75109177e-01,  9.67830374e-02],\n",
              "       [-9.62638004e-01,  3.38961564e-02],\n",
              "       [-1.55434609e+00,  1.22185275e-01],\n",
              "       [-1.56155049e+00,  1.97634446e-01],\n",
              "       [-1.23065281e+00,  1.38522788e-01],\n",
              "       [-1.28911697e+00, -2.45712372e-02],\n",
              "       [-1.03365341e+00,  4.55549306e-01],\n",
              "       [-8.04952110e-01,  3.19095665e-01],\n",
              "       [-3.94639905e-01, -1.23657456e+00],\n",
              "       [-1.97329801e-02, -6.75147214e-01],\n",
              "       [ 6.69018597e-01,  2.48361780e-01],\n",
              "       [ 4.22553872e-02, -5.89378504e-01],\n",
              "       [-1.27992401e+00,  1.99300132e-02],\n",
              "       [-7.06552566e-01,  6.67642305e-01],\n",
              "       [-1.35357770e+00,  1.82867923e-01],\n",
              "       [-1.23612794e+00,  4.50508724e-01],\n",
              "       [-9.57476607e-01, -3.83597162e-01],\n",
              "       [-7.44356993e-01,  2.24729621e-01],\n",
              "       [ 1.93233756e-01,  8.74199638e-01],\n",
              "       [ 1.01687762e-01,  1.29665797e+00],\n",
              "       [ 7.50314593e+00, -1.44344493e+00],\n",
              "       [-4.19386275e-01, -6.27545427e-01],\n",
              "       [ 1.56702096e-01, -1.88579075e-01],\n",
              "       [ 1.63623151e+00, -2.57833010e+00],\n",
              "       [ 2.05836675e+00,  1.44282284e-01],\n",
              "       [-8.44404965e-01, -1.08609511e+00],\n",
              "       [ 2.91953363e-01, -1.19405701e+00],\n",
              "       [-5.21349195e-01, -3.21420637e-01],\n",
              "       [-6.17529824e-01,  1.20244137e+00],\n",
              "       [-9.49071559e-01, -3.22702830e-02],\n",
              "       [-1.26053224e+00,  1.44311458e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(data_frame=temp_df,x=X_embedded[:,0], y=X_embedded[:,1],hover_name=viz_df['channel name'])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "v-vuynJxWeja",
        "outputId": "e06a5e93-a732-4c95-ae6b-8ce6c763b95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"49b9d98e-37fe-4a7b-a046-b727e7dd47ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"49b9d98e-37fe-4a7b-a046-b727e7dd47ad\")) {                    Plotly.newPlot(                        \"49b9d98e-37fe-4a7b-a046-b727e7dd47ad\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Data School\",\"Bhavesh Bhatt\",\"Unfold Data Science\",\"Abhishek Thakur\",\"AppliedAI\",\"5 minutes engineering\",\"Serrano Academy\",\"Krish Naik\",\"Codebasics\",\"Statquest\",\"CampusX\",\"Satyajit Pattnaik\",\"Daniel Bourke\",\"Deeplizard\",\"Ken Jee\",\"Python Engineer\",\"KGPTalkie\",\"AI Engineering\",\"Nicolas Renotte\",\"Siddaharan\",\"Indian AI Production\",\"The AI University\",\"Harshit Tyagi\",\"Developer Ashish\",\"Normalized Nerd\",\"Smitha Kolan\",\"Shashank Kalanithi\",\"DigitalSreeni\",\"Brandon Rohrer\",\"Ranji Raj\",\"Abhishek Agarrwal\",\"Deeplearning.ai\",\"Deep Learning in Hindi\",\"Fahad Hussain\",\"Data Science Jay\",\"Sundas Khalid\",\"Seattle Data Guy\",\"Data Professor\",\"Tina Huang\",\"Data Science Career Coach\",\"Sentdex\",\"Data Science Dojo\",\"Data Science Tutorials\",\"Brandon Foltz\",\"Datacamp\",\"The Semiclon\",\"Ritvikmath\",\"kaggle\",\"ineuron\",\"Springboard\",\"Jovian\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.5758238346920772,-0.6813936232635546,-0.8317629583015453,-1.1563984399291485,0.006542337184817755,3.606197885669675,-0.4539601670229908,4.838832669017103,3.7233863717765003,3.9496739676386694,-0.2483189057542146,-1.276073198256755,-0.5754274214975578,-0.1385775434943804,-0.12230336656330347,0.06162583438537918,-0.4141524854858014,-0.9882759678671048,-0.6365705957121439,-1.374781559666218,-0.7751091773526544,-0.9626380043267844,-1.554346094082445,-1.5615504891860217,-1.2306528091940598,-1.2891169708346917,-1.033653407688758,-0.8049521100119501,-0.39463990496708534,-0.019732980087007752,0.6690185965076312,0.04225538719611064,-1.2799240065799802,-0.7065525660670485,-1.3535776976171783,-1.2361279411590576,-0.9574766067262662,-0.7443569927557064,0.19323375571423776,0.10168776152105564,7.503145929703762,-0.4193862745464176,0.15670209631880752,1.6362315146790491,2.058366745520511,-0.8444049651914475,0.2919533633129538,-0.5213491952197532,-0.6175298237798332,-0.9490715592482891,-1.2605322414011848],\"xaxis\":\"x\",\"y\":[-2.1661466701539767,-0.4227829035903831,0.17400976221047862,0.1587594845198866,-0.30308294944734965,2.605066386369369,-1.2179819625207864,2.1550812723212665,0.3058987565649209,-0.48337633424371235,1.3066775911519106,0.5599072821164136,-0.08335971891923223,-0.3841691138460037,-0.518265175136109,0.8285459363560564,0.08310312325059786,0.15259457574532026,0.1557947304567066,0.6551374167833495,0.09678303739685391,0.033896156424549,0.12218527459424212,0.19763444635508462,0.13852278763456374,-0.02457123722246545,0.455549306061509,0.31909566538926404,-1.2365745557998382,-0.6751472140448945,0.24836177993224104,-0.5893785041794517,0.019930013182631108,0.6676423054701642,0.1828679225000657,0.4505087238673333,-0.38359716190812354,0.22472962129849847,0.8741996382158992,1.2966579702027459,-1.4434449297371015,-0.6275454274136498,-0.18857907521145262,-2.578330102494338,0.14428228383551206,-1.086095113341753,-1.1940570067549854,-0.32142063731708465,1.2024413680804245,-0.03227028297097339,0.1443114579658068],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('49b9d98e-37fe-4a7b-a046-b727e7dd47ad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hona kitta chahiye tha?\n",
        "# prepare data\n",
        "index_of_campusx = np.where(df['channel name'] == 'CampusX')[0][0]\n",
        "\n",
        "X_df = df[['views','last 30 days views','num videos','old','subs']]\n",
        "\n",
        "X_df['subs'] = X_df['subs']/1000\n",
        "\n",
        "X_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yKeBtXqvXjhu",
        "outputId": "4a619432-e1ee-4028-ad5b-83f9aadcfc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          views  last 30 days views  num videos   old     subs\n",
              "0     9730000.0            106000.0         138  2945   193.00\n",
              "1     2720000.0             72700.0         292  1509    37.40\n",
              "2     1720000.0            123000.0         369  1085    27.90\n",
              "3     1740000.0             59600.0         139   764    69.80\n",
              "4    13200000.0             98600.0         497  1583    77.90\n",
              "5    37900000.0           1610000.0        1390  1260   303.00\n",
              "6     4770000.0             70200.0          43  1967    96.40\n",
              "7    51100000.0           1650000.0        1360  1525   556.00\n",
              "8    35000000.0           1470000.0         493  2231   557.00\n",
              "9    35900000.0           1390000.0         217  2524   702.00\n",
              "10    1500000.0            198000.0        1100   859    18.00\n",
              "11     480000.0             56400.0         305   582    19.40\n",
              "12    5280000.0             84900.0         291  1149   112.00\n",
              "13    9330000.0            167000.0         307  1531   117.00\n",
              "14    6060000.0            153000.0         230  1531   195.00\n",
              "15    6960000.0            823000.0         163   978   115.00\n",
              "16    4450000.0             88800.0         593  1352    39.80\n",
              "17    1950000.0             61400.0         261   903    62.20\n",
              "18    3440000.0            312000.0         181  1094    67.90\n",
              "19    1020000.0            118000.0         138   369    48.60\n",
              "20    3530000.0            119000.0         342  1118    31.90\n",
              "21    1330000.0             46200.0         332  1096    24.00\n",
              "22     180000.0              5240.0          44   676     8.03\n",
              "23     320000.0             13300.0          39   603    16.20\n",
              "24    1300000.0            117000.0          88   818    30.60\n",
              "25    1090000.0             45400.0          66   866    37.80\n",
              "26    3260000.0            202000.0         111   602    81.90\n",
              "27    2570000.0            198000.0         316   968    38.40\n",
              "28    4390000.0             46500.0         145  2076    77.30\n",
              "29    6210000.0            116000.0         539  2044    42.30\n",
              "30    7430000.0            196000.0        1190  1920    60.58\n",
              "31   11300000.0            181000.0         219  1616   170.00\n",
              "32     330000.0              8410.0         201   943     4.47\n",
              "33    1310000.0             46500.0         741   923    16.10\n",
              "34     970000.0             66600.0          95   731    22.40\n",
              "35    2150000.0            174000.0          51   525    64.70\n",
              "36    1200000.0            108000.0         122  1345    26.00\n",
              "37    2790000.0            130000.0         272   892   116.00\n",
              "38   10800000.0            651000.0          92   555   294.00\n",
              "39    1540000.0            124000.0        1410  1103    28.00\n",
              "40  101000000.0            588000.0        1250  3178  1110.00\n",
              "41    4690000.0             66500.0         297  1672    82.70\n",
              "42    3890000.0            130000.0         869  1950    38.10\n",
              "43   23200000.0            179000.0         259  3468   262.00\n",
              "44   20800000.0            627000.0        1240  2483   129.00\n",
              "45    2170000.0             20300.0          46  1835    23.50\n",
              "46    5780000.0            215000.0         415  2504    79.90\n",
              "47    2940000.0             55600.0         346  1413   103.00\n",
              "48    1130000.0            705000.0         193   576    41.70\n",
              "49    3900000.0            141000.0         108  1009    53.00\n",
              "50     950000.0             59700.0         148   813    27.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c98a3174-0297-44da-88eb-5cd5e3592394\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>views</th>\n",
              "      <th>last 30 days views</th>\n",
              "      <th>num videos</th>\n",
              "      <th>old</th>\n",
              "      <th>subs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9730000.0</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>2945</td>\n",
              "      <td>193.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2720000.0</td>\n",
              "      <td>72700.0</td>\n",
              "      <td>292</td>\n",
              "      <td>1509</td>\n",
              "      <td>37.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1720000.0</td>\n",
              "      <td>123000.0</td>\n",
              "      <td>369</td>\n",
              "      <td>1085</td>\n",
              "      <td>27.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1740000.0</td>\n",
              "      <td>59600.0</td>\n",
              "      <td>139</td>\n",
              "      <td>764</td>\n",
              "      <td>69.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13200000.0</td>\n",
              "      <td>98600.0</td>\n",
              "      <td>497</td>\n",
              "      <td>1583</td>\n",
              "      <td>77.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37900000.0</td>\n",
              "      <td>1610000.0</td>\n",
              "      <td>1390</td>\n",
              "      <td>1260</td>\n",
              "      <td>303.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4770000.0</td>\n",
              "      <td>70200.0</td>\n",
              "      <td>43</td>\n",
              "      <td>1967</td>\n",
              "      <td>96.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>51100000.0</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>1360</td>\n",
              "      <td>1525</td>\n",
              "      <td>556.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35000000.0</td>\n",
              "      <td>1470000.0</td>\n",
              "      <td>493</td>\n",
              "      <td>2231</td>\n",
              "      <td>557.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>35900000.0</td>\n",
              "      <td>1390000.0</td>\n",
              "      <td>217</td>\n",
              "      <td>2524</td>\n",
              "      <td>702.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1500000.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>1100</td>\n",
              "      <td>859</td>\n",
              "      <td>18.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>480000.0</td>\n",
              "      <td>56400.0</td>\n",
              "      <td>305</td>\n",
              "      <td>582</td>\n",
              "      <td>19.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5280000.0</td>\n",
              "      <td>84900.0</td>\n",
              "      <td>291</td>\n",
              "      <td>1149</td>\n",
              "      <td>112.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>9330000.0</td>\n",
              "      <td>167000.0</td>\n",
              "      <td>307</td>\n",
              "      <td>1531</td>\n",
              "      <td>117.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6060000.0</td>\n",
              "      <td>153000.0</td>\n",
              "      <td>230</td>\n",
              "      <td>1531</td>\n",
              "      <td>195.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6960000.0</td>\n",
              "      <td>823000.0</td>\n",
              "      <td>163</td>\n",
              "      <td>978</td>\n",
              "      <td>115.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4450000.0</td>\n",
              "      <td>88800.0</td>\n",
              "      <td>593</td>\n",
              "      <td>1352</td>\n",
              "      <td>39.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1950000.0</td>\n",
              "      <td>61400.0</td>\n",
              "      <td>261</td>\n",
              "      <td>903</td>\n",
              "      <td>62.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3440000.0</td>\n",
              "      <td>312000.0</td>\n",
              "      <td>181</td>\n",
              "      <td>1094</td>\n",
              "      <td>67.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1020000.0</td>\n",
              "      <td>118000.0</td>\n",
              "      <td>138</td>\n",
              "      <td>369</td>\n",
              "      <td>48.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3530000.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>342</td>\n",
              "      <td>1118</td>\n",
              "      <td>31.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1330000.0</td>\n",
              "      <td>46200.0</td>\n",
              "      <td>332</td>\n",
              "      <td>1096</td>\n",
              "      <td>24.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>44</td>\n",
              "      <td>676</td>\n",
              "      <td>8.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>320000.0</td>\n",
              "      <td>13300.0</td>\n",
              "      <td>39</td>\n",
              "      <td>603</td>\n",
              "      <td>16.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1300000.0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>88</td>\n",
              "      <td>818</td>\n",
              "      <td>30.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1090000.0</td>\n",
              "      <td>45400.0</td>\n",
              "      <td>66</td>\n",
              "      <td>866</td>\n",
              "      <td>37.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3260000.0</td>\n",
              "      <td>202000.0</td>\n",
              "      <td>111</td>\n",
              "      <td>602</td>\n",
              "      <td>81.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2570000.0</td>\n",
              "      <td>198000.0</td>\n",
              "      <td>316</td>\n",
              "      <td>968</td>\n",
              "      <td>38.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>4390000.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>145</td>\n",
              "      <td>2076</td>\n",
              "      <td>77.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6210000.0</td>\n",
              "      <td>116000.0</td>\n",
              "      <td>539</td>\n",
              "      <td>2044</td>\n",
              "      <td>42.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>7430000.0</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1190</td>\n",
              "      <td>1920</td>\n",
              "      <td>60.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>11300000.0</td>\n",
              "      <td>181000.0</td>\n",
              "      <td>219</td>\n",
              "      <td>1616</td>\n",
              "      <td>170.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>330000.0</td>\n",
              "      <td>8410.0</td>\n",
              "      <td>201</td>\n",
              "      <td>943</td>\n",
              "      <td>4.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1310000.0</td>\n",
              "      <td>46500.0</td>\n",
              "      <td>741</td>\n",
              "      <td>923</td>\n",
              "      <td>16.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>970000.0</td>\n",
              "      <td>66600.0</td>\n",
              "      <td>95</td>\n",
              "      <td>731</td>\n",
              "      <td>22.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2150000.0</td>\n",
              "      <td>174000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>525</td>\n",
              "      <td>64.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1200000.0</td>\n",
              "      <td>108000.0</td>\n",
              "      <td>122</td>\n",
              "      <td>1345</td>\n",
              "      <td>26.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2790000.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>272</td>\n",
              "      <td>892</td>\n",
              "      <td>116.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>10800000.0</td>\n",
              "      <td>651000.0</td>\n",
              "      <td>92</td>\n",
              "      <td>555</td>\n",
              "      <td>294.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1540000.0</td>\n",
              "      <td>124000.0</td>\n",
              "      <td>1410</td>\n",
              "      <td>1103</td>\n",
              "      <td>28.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>101000000.0</td>\n",
              "      <td>588000.0</td>\n",
              "      <td>1250</td>\n",
              "      <td>3178</td>\n",
              "      <td>1110.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4690000.0</td>\n",
              "      <td>66500.0</td>\n",
              "      <td>297</td>\n",
              "      <td>1672</td>\n",
              "      <td>82.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3890000.0</td>\n",
              "      <td>130000.0</td>\n",
              "      <td>869</td>\n",
              "      <td>1950</td>\n",
              "      <td>38.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>23200000.0</td>\n",
              "      <td>179000.0</td>\n",
              "      <td>259</td>\n",
              "      <td>3468</td>\n",
              "      <td>262.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>20800000.0</td>\n",
              "      <td>627000.0</td>\n",
              "      <td>1240</td>\n",
              "      <td>2483</td>\n",
              "      <td>129.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2170000.0</td>\n",
              "      <td>20300.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1835</td>\n",
              "      <td>23.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5780000.0</td>\n",
              "      <td>215000.0</td>\n",
              "      <td>415</td>\n",
              "      <td>2504</td>\n",
              "      <td>79.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2940000.0</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>346</td>\n",
              "      <td>1413</td>\n",
              "      <td>103.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1130000.0</td>\n",
              "      <td>705000.0</td>\n",
              "      <td>193</td>\n",
              "      <td>576</td>\n",
              "      <td>41.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3900000.0</td>\n",
              "      <td>141000.0</td>\n",
              "      <td>108</td>\n",
              "      <td>1009</td>\n",
              "      <td>53.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>950000.0</td>\n",
              "      <td>59700.0</td>\n",
              "      <td>148</td>\n",
              "      <td>813</td>\n",
              "      <td>27.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c98a3174-0297-44da-88eb-5cd5e3592394')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c98a3174-0297-44da-88eb-5cd5e3592394 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c98a3174-0297-44da-88eb-5cd5e3592394');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_input = scaler.fit_transform(X_df.iloc[:,:-1])"
      ],
      "metadata": {
        "id": "aypjEuC9bxHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "campusx_input = X_input[10]"
      ],
      "metadata": {
        "id": "D3Q7OrkDcDFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the campusx row\n",
        "X_input = np.delete(X_input,(10), axis=0)"
      ],
      "metadata": {
        "id": "FO4ec6YRc9Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X_df.iloc[:,-1].values\n",
        "y = np.delete(y,(10))"
      ],
      "metadata": {
        "id": "4gt8qEahdQX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "r6CHI6-XdUQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10,activation='relu',input_dim=4))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "metadata": {
        "id": "HzMn5rr2dvQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1d9K8IyeFEL",
        "outputId": "80c2fce2-4b09-4b6b-ea83-44c75bdde5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 10)                50        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 501\n",
            "Trainable params: 501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "HDxC8dSBeIMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_input,y,epochs=1000,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-37vPa5eY13",
        "outputId": "1d9c15e8-a6a7-4f2a-ac01-c1fc73d4ce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 2s 330ms/step - loss: 138.5218 - val_loss: 60.9175\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 138.5066 - val_loss: 60.9050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 138.4930 - val_loss: 60.8919\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 138.4806 - val_loss: 60.8798\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 138.4680 - val_loss: 60.8679\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 138.4537 - val_loss: 60.8562\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 138.4395 - val_loss: 60.8439\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 138.4250 - val_loss: 60.8309\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 138.4089 - val_loss: 60.8162\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 138.3932 - val_loss: 60.8023\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 138.3763 - val_loss: 60.7891\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 138.3570 - val_loss: 60.7753\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 138.3400 - val_loss: 60.7610\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 138.3215 - val_loss: 60.7454\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 138.3029 - val_loss: 60.7292\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 138.2826 - val_loss: 60.7125\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 138.2610 - val_loss: 60.6951\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 138.2415 - val_loss: 60.6771\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 138.2182 - val_loss: 60.6586\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 138.1953 - val_loss: 60.6392\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 138.1707 - val_loss: 60.6190\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 138.1453 - val_loss: 60.5976\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 138.1160 - val_loss: 60.5745\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 138.0871 - val_loss: 60.5501\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 138.0557 - val_loss: 60.5246\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 138.0217 - val_loss: 60.4976\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 137.9873 - val_loss: 60.4694\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 137.9481 - val_loss: 60.4393\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 137.9101 - val_loss: 60.4064\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 137.8678 - val_loss: 60.3711\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 137.8228 - val_loss: 60.3337\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 137.7757 - val_loss: 60.2945\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 137.7249 - val_loss: 60.2532\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 137.6723 - val_loss: 60.2090\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 137.6149 - val_loss: 60.1622\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 137.5517 - val_loss: 60.1127\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 137.4877 - val_loss: 60.0602\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 137.4181 - val_loss: 60.0046\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 137.3453 - val_loss: 59.9454\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 137.2673 - val_loss: 59.8828\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 137.1844 - val_loss: 59.8151\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 137.0963 - val_loss: 59.7436\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 136.9973 - val_loss: 59.6676\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 136.9030 - val_loss: 59.5868\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 136.7959 - val_loss: 59.5003\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 136.6805 - val_loss: 59.4085\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 136.5645 - val_loss: 59.3102\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 136.4276 - val_loss: 59.2046\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 136.2986 - val_loss: 59.0911\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 136.1516 - val_loss: 58.9695\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 135.9908 - val_loss: 58.8398\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 135.8225 - val_loss: 58.7010\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 135.6304 - val_loss: 58.5514\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 135.4461 - val_loss: 58.3906\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 135.2252 - val_loss: 58.2192\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 135.0106 - val_loss: 58.0350\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 134.7762 - val_loss: 57.8384\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 134.4986 - val_loss: 57.6289\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 134.2305 - val_loss: 57.4000\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 133.9458 - val_loss: 57.1546\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 133.6252 - val_loss: 56.8934\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 133.2820 - val_loss: 56.6152\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 132.9367 - val_loss: 56.3189\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 132.5614 - val_loss: 56.0054\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 132.1694 - val_loss: 55.6727\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 131.7560 - val_loss: 55.3194\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 131.3106 - val_loss: 54.9429\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 130.8700 - val_loss: 54.5413\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 130.3286 - val_loss: 54.1157\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 129.8412 - val_loss: 53.6604\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 129.2856 - val_loss: 53.1791\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 128.7138 - val_loss: 52.6703\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 128.1593 - val_loss: 52.1318\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 127.5115 - val_loss: 51.5633\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 126.8291 - val_loss: 50.9598\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 126.1601 - val_loss: 50.3184\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 125.3800 - val_loss: 49.6416\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 124.6161 - val_loss: 48.9242\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 123.7672 - val_loss: 48.1651\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 122.9052 - val_loss: 47.3604\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 121.9563 - val_loss: 46.5126\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 120.9926 - val_loss: 45.6064\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 120.0808 - val_loss: 44.6603\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 119.1469 - val_loss: 43.6926\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 118.1387 - val_loss: 42.6916\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 117.1498 - val_loss: 41.6375\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 116.0921 - val_loss: 40.5464\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 115.0695 - val_loss: 39.4169\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 113.9448 - val_loss: 38.2401\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 112.7893 - val_loss: 36.9897\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 111.5805 - val_loss: 36.1940\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 110.3636 - val_loss: 35.4248\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 109.0881 - val_loss: 34.6316\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 107.8820 - val_loss: 33.8025\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 106.4459 - val_loss: 32.9470\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 105.3896 - val_loss: 32.0686\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 104.0002 - val_loss: 31.1986\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 102.7976 - val_loss: 30.3166\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 101.8146 - val_loss: 29.4480\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 100.5808 - val_loss: 28.6244\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 99.5997 - val_loss: 27.8109\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 98.5409 - val_loss: 26.9967\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 97.5569 - val_loss: 26.1822\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 96.8965 - val_loss: 25.6226\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 95.8721 - val_loss: 25.2398\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 94.9540 - val_loss: 24.8479\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 93.9994 - val_loss: 24.4382\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 93.1380 - val_loss: 24.0093\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 91.9980 - val_loss: 23.5891\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 91.4058 - val_loss: 23.1584\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 90.6077 - val_loss: 22.7476\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 89.7604 - val_loss: 22.3543\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 88.9430 - val_loss: 21.9685\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 88.2295 - val_loss: 21.5870\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 87.2761 - val_loss: 21.3106\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 86.6640 - val_loss: 21.8046\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 85.7173 - val_loss: 22.2775\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 84.8545 - val_loss: 22.7754\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 84.0279 - val_loss: 23.3325\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 83.1199 - val_loss: 23.9116\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 82.0529 - val_loss: 24.4958\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 81.0478 - val_loss: 25.1150\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 79.9530 - val_loss: 25.7834\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 79.0351 - val_loss: 26.4758\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 77.6488 - val_loss: 27.1372\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 76.6453 - val_loss: 27.8285\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 75.2424 - val_loss: 28.5383\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 74.1036 - val_loss: 29.3822\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 72.8885 - val_loss: 30.3617\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 71.7194 - val_loss: 31.2771\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 70.3093 - val_loss: 32.1011\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 68.8011 - val_loss: 32.9858\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 67.6528 - val_loss: 33.9637\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 66.2645 - val_loss: 34.8543\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 65.9090 - val_loss: 35.5595\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 65.0471 - val_loss: 35.9260\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 64.1962 - val_loss: 36.1504\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 63.7050 - val_loss: 36.4656\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 63.0544 - val_loss: 36.7809\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 62.5688 - val_loss: 37.0728\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 61.9539 - val_loss: 37.3340\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 61.3808 - val_loss: 37.6849\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 60.7611 - val_loss: 38.0960\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 60.2176 - val_loss: 38.5009\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 59.7742 - val_loss: 38.7914\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 59.2672 - val_loss: 38.9981\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 58.8608 - val_loss: 39.1705\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 58.4512 - val_loss: 39.3757\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 58.0494 - val_loss: 39.5443\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 57.6857 - val_loss: 39.7127\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 57.2880 - val_loss: 39.8569\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 56.8737 - val_loss: 40.0136\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 56.5045 - val_loss: 40.3128\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 56.0598 - val_loss: 40.5991\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 55.7362 - val_loss: 40.8532\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 55.2605 - val_loss: 41.0035\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 54.9099 - val_loss: 41.0949\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 54.4108 - val_loss: 41.1032\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 54.1111 - val_loss: 41.1333\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 53.7303 - val_loss: 41.1334\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 53.3844 - val_loss: 41.1248\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 53.0545 - val_loss: 41.1610\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 52.7171 - val_loss: 41.2667\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 52.3398 - val_loss: 41.3962\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 51.9547 - val_loss: 41.5390\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 51.6924 - val_loss: 41.6400\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 51.1782 - val_loss: 41.6355\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 50.8638 - val_loss: 41.6692\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 50.6847 - val_loss: 41.7046\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 50.3003 - val_loss: 41.5779\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 50.0667 - val_loss: 41.4185\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 49.8863 - val_loss: 41.1950\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 49.6423 - val_loss: 41.0480\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 49.4770 - val_loss: 40.9983\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 49.2483 - val_loss: 41.0759\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 49.0904 - val_loss: 41.0469\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 48.8694 - val_loss: 40.9028\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 48.6959 - val_loss: 40.7207\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 48.6425 - val_loss: 40.6218\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 48.4539 - val_loss: 40.7005\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 48.2872 - val_loss: 40.8059\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 48.1223 - val_loss: 40.8132\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 47.9659 - val_loss: 40.7854\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 47.8647 - val_loss: 40.7436\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 47.7095 - val_loss: 40.7097\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 47.5425 - val_loss: 40.5630\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 47.4397 - val_loss: 40.3807\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 47.2806 - val_loss: 40.3472\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 47.1582 - val_loss: 40.3777\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 46.9782 - val_loss: 40.4796\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 46.8215 - val_loss: 40.5733\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 46.6671 - val_loss: 40.5826\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 46.5271 - val_loss: 40.5988\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 46.4154 - val_loss: 40.6163\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 46.2867 - val_loss: 40.6240\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 46.1286 - val_loss: 40.6803\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 45.9944 - val_loss: 40.7232\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 45.8816 - val_loss: 40.7833\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 45.6969 - val_loss: 40.9568\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 45.5716 - val_loss: 41.1707\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 45.4697 - val_loss: 41.4296\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 45.4426 - val_loss: 41.6343\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 45.2525 - val_loss: 41.7685\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 45.1840 - val_loss: 41.9148\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 45.0124 - val_loss: 41.9634\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 44.8700 - val_loss: 41.9815\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 44.7961 - val_loss: 41.9485\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 44.5840 - val_loss: 41.7953\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 44.4475 - val_loss: 41.6585\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 44.2578 - val_loss: 41.5890\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 44.0858 - val_loss: 41.5151\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 43.9368 - val_loss: 41.4166\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 43.7875 - val_loss: 41.2993\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 43.5556 - val_loss: 41.0616\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 43.3629 - val_loss: 40.7526\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 43.2940 - val_loss: 40.4024\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 42.9988 - val_loss: 40.1472\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 42.8474 - val_loss: 39.8735\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 42.6506 - val_loss: 39.6235\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 42.5849 - val_loss: 39.4534\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 42.5026 - val_loss: 39.4509\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 42.3545 - val_loss: 39.5546\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 42.0205 - val_loss: 39.6497\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 41.8648 - val_loss: 39.7161\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 41.7071 - val_loss: 39.7705\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 41.5736 - val_loss: 39.7827\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 41.3430 - val_loss: 39.6691\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 41.1633 - val_loss: 39.5675\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 41.0490 - val_loss: 39.4666\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 40.8193 - val_loss: 39.4456\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 40.6807 - val_loss: 39.3440\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 40.4645 - val_loss: 39.1430\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 40.3070 - val_loss: 38.8907\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 40.2730 - val_loss: 38.7655\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 40.2575 - val_loss: 38.7719\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 40.0157 - val_loss: 38.9938\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 39.8663 - val_loss: 39.2719\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 39.8224 - val_loss: 39.3700\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 39.8290 - val_loss: 39.2869\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 39.6953 - val_loss: 39.0406\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 39.5040 - val_loss: 38.7004\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 39.6533 - val_loss: 38.5437\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 39.5796 - val_loss: 38.6803\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 39.3740 - val_loss: 38.9604\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 39.2221 - val_loss: 39.1893\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 39.2896 - val_loss: 39.3090\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 39.2618 - val_loss: 39.2956\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 39.1661 - val_loss: 39.1496\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 39.1032 - val_loss: 38.9287\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 38.9051 - val_loss: 38.8184\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 38.8636 - val_loss: 38.7426\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 38.8121 - val_loss: 38.7910\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 38.7407 - val_loss: 38.8632\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 38.6504 - val_loss: 38.7792\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 38.5361 - val_loss: 38.5850\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 38.4847 - val_loss: 38.3708\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 38.5491 - val_loss: 38.2525\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 38.5594 - val_loss: 38.1894\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 38.4288 - val_loss: 38.2992\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 38.2561 - val_loss: 38.3218\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 38.2320 - val_loss: 38.2876\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 38.0972 - val_loss: 38.3735\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 38.1009 - val_loss: 38.3705\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 38.0799 - val_loss: 38.2852\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 37.9880 - val_loss: 38.2117\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 37.8758 - val_loss: 38.0146\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 37.7960 - val_loss: 37.9585\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 37.7215 - val_loss: 38.0462\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 37.7023 - val_loss: 38.0613\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 37.6172 - val_loss: 37.9305\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 37.5121 - val_loss: 37.7258\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 37.5705 - val_loss: 37.6564\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 37.5401 - val_loss: 37.7289\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 37.3661 - val_loss: 37.7629\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 37.2906 - val_loss: 37.7802\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 37.2628 - val_loss: 37.7234\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 37.2103 - val_loss: 37.6567\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 37.1478 - val_loss: 37.5871\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 37.0795 - val_loss: 37.4787\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 36.9802 - val_loss: 37.4514\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 36.9615 - val_loss: 37.4421\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 36.8713 - val_loss: 37.4045\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 36.8418 - val_loss: 37.4032\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 36.7407 - val_loss: 37.2535\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 36.6517 - val_loss: 37.1324\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 36.6245 - val_loss: 37.1005\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 36.5210 - val_loss: 36.9781\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 36.4675 - val_loss: 36.8114\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 36.4781 - val_loss: 36.8032\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 36.3877 - val_loss: 36.8958\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 36.3224 - val_loss: 36.9042\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 36.2830 - val_loss: 36.8794\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 36.1834 - val_loss: 36.8082\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 36.0757 - val_loss: 36.7066\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 36.0326 - val_loss: 36.6342\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 36.0526 - val_loss: 36.5961\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 35.9828 - val_loss: 36.5961\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 35.8469 - val_loss: 36.7073\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 35.7238 - val_loss: 36.7760\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 35.8054 - val_loss: 36.7301\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 35.6291 - val_loss: 36.5148\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 35.5307 - val_loss: 36.3420\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 35.5616 - val_loss: 36.2889\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 35.4705 - val_loss: 36.3917\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 35.4056 - val_loss: 36.5802\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 35.2875 - val_loss: 36.6426\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 35.3263 - val_loss: 36.6749\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 35.3319 - val_loss: 36.6017\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 35.1904 - val_loss: 36.3851\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 35.1377 - val_loss: 36.0900\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 34.8675 - val_loss: 35.9275\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 34.8348 - val_loss: 35.8367\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 34.7794 - val_loss: 35.8790\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 34.6048 - val_loss: 35.9610\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 34.6192 - val_loss: 36.0597\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 34.6135 - val_loss: 36.0790\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 34.5786 - val_loss: 36.0247\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 34.5105 - val_loss: 35.9547\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 34.3807 - val_loss: 35.9219\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 34.2722 - val_loss: 35.8341\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 34.1208 - val_loss: 35.6976\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 34.0026 - val_loss: 35.5470\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 34.0345 - val_loss: 35.4900\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 33.9517 - val_loss: 35.5568\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 33.7793 - val_loss: 35.6113\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 33.6811 - val_loss: 35.5758\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 33.6031 - val_loss: 35.4382\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 33.4534 - val_loss: 35.2276\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 33.6042 - val_loss: 35.0698\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 33.5781 - val_loss: 35.1050\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 33.3527 - val_loss: 35.1590\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 33.1227 - val_loss: 35.2041\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 33.0858 - val_loss: 35.1922\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 33.0182 - val_loss: 35.1529\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 32.9623 - val_loss: 35.0817\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 32.7851 - val_loss: 35.0496\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 32.6517 - val_loss: 34.9617\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 32.5975 - val_loss: 34.8866\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 32.5316 - val_loss: 34.8903\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 32.4242 - val_loss: 34.8491\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 32.2801 - val_loss: 34.7400\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 32.1492 - val_loss: 34.5930\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 32.0536 - val_loss: 34.4844\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 31.9511 - val_loss: 34.3943\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 31.7935 - val_loss: 34.3939\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 31.6702 - val_loss: 34.4784\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 31.6895 - val_loss: 34.5130\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 31.5157 - val_loss: 34.3925\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 31.3531 - val_loss: 34.2091\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 31.1857 - val_loss: 33.9604\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 31.0892 - val_loss: 33.8043\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 30.9987 - val_loss: 33.8221\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 30.8523 - val_loss: 33.8637\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 30.7053 - val_loss: 33.7821\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 30.5684 - val_loss: 33.6233\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 30.4908 - val_loss: 33.4722\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 30.5134 - val_loss: 33.4403\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 30.4574 - val_loss: 33.5633\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 30.1998 - val_loss: 33.5307\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 30.1144 - val_loss: 33.4407\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 29.9789 - val_loss: 33.3751\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 29.8677 - val_loss: 33.2745\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 29.7033 - val_loss: 33.1920\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 29.5331 - val_loss: 33.0655\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 29.4530 - val_loss: 32.9641\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 29.2949 - val_loss: 32.8963\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 29.1596 - val_loss: 32.8668\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 29.1028 - val_loss: 32.8439\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 29.0482 - val_loss: 32.6284\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 28.7854 - val_loss: 32.3301\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 28.8103 - val_loss: 32.0953\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 28.7598 - val_loss: 31.9613\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 28.7535 - val_loss: 31.9519\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 28.6765 - val_loss: 32.1007\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 28.4730 - val_loss: 32.0926\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 28.4708 - val_loss: 31.9809\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 28.2871 - val_loss: 31.7162\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 28.3255 - val_loss: 31.4792\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 28.3930 - val_loss: 31.5043\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 28.1323 - val_loss: 31.7245\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 28.1569 - val_loss: 31.8127\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 28.2624 - val_loss: 31.7028\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 28.0984 - val_loss: 31.4964\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 27.7883 - val_loss: 31.2974\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 27.7737 - val_loss: 31.1460\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 27.8751 - val_loss: 31.1599\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 27.7668 - val_loss: 31.3217\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 27.4574 - val_loss: 31.4636\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 27.5175 - val_loss: 31.5241\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 27.5356 - val_loss: 31.4461\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 27.4190 - val_loss: 31.3038\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 27.1696 - val_loss: 31.2467\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 27.1510 - val_loss: 31.2220\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 27.1282 - val_loss: 31.2425\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 27.0217 - val_loss: 31.2468\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 26.9124 - val_loss: 31.2643\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 26.8425 - val_loss: 31.2117\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 26.7643 - val_loss: 31.2531\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 26.7129 - val_loss: 31.2261\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 26.6245 - val_loss: 31.1954\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 26.5267 - val_loss: 31.2376\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 26.5684 - val_loss: 31.2058\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 26.5258 - val_loss: 31.0978\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 26.4268 - val_loss: 30.9536\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 26.3009 - val_loss: 30.9312\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 26.2742 - val_loss: 30.9633\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 26.1231 - val_loss: 31.1351\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 26.1652 - val_loss: 31.2129\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 26.1156 - val_loss: 31.1466\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 25.9036 - val_loss: 30.9480\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 26.0268 - val_loss: 30.7891\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 25.9411 - val_loss: 30.8224\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 25.8165 - val_loss: 30.9650\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 25.6312 - val_loss: 31.0899\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 25.5695 - val_loss: 31.0793\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 25.5352 - val_loss: 30.9928\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 25.4348 - val_loss: 30.9043\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 25.3027 - val_loss: 30.7628\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 25.2471 - val_loss: 30.6500\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 25.2544 - val_loss: 30.6241\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 25.1801 - val_loss: 30.6775\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 25.0340 - val_loss: 30.7581\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 24.9028 - val_loss: 30.7555\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 24.8601 - val_loss: 30.7008\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 24.8190 - val_loss: 30.6453\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 24.7247 - val_loss: 30.6558\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 24.7235 - val_loss: 30.5702\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 24.6281 - val_loss: 30.3636\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 24.5778 - val_loss: 30.2654\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 24.5433 - val_loss: 30.2666\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 24.3943 - val_loss: 30.3848\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 24.4198 - val_loss: 30.4840\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 24.5404 - val_loss: 30.4355\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 24.3555 - val_loss: 30.2094\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 24.1252 - val_loss: 29.9182\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 24.1978 - val_loss: 29.7019\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 24.4881 - val_loss: 29.6605\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 24.3790 - val_loss: 29.8437\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 24.0075 - val_loss: 30.1797\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 23.7419 - val_loss: 30.4561\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 23.9161 - val_loss: 30.6156\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 24.0157 - val_loss: 30.6058\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 23.8645 - val_loss: 30.4235\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 23.5781 - val_loss: 30.1358\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 23.4980 - val_loss: 29.8469\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 23.7042 - val_loss: 29.6939\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 23.7034 - val_loss: 29.6236\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 23.6707 - val_loss: 29.5823\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 23.6266 - val_loss: 29.5883\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 23.4786 - val_loss: 29.7206\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 23.1171 - val_loss: 29.8586\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 22.9545 - val_loss: 30.1342\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 23.1113 - val_loss: 30.2505\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 23.2442 - val_loss: 30.2128\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 23.1670 - val_loss: 30.0546\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 22.9542 - val_loss: 29.8214\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 22.7280 - val_loss: 29.5812\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 22.5784 - val_loss: 29.3066\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 22.8480 - val_loss: 29.1582\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 22.8732 - val_loss: 29.1753\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 22.7490 - val_loss: 29.3121\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 22.6720 - val_loss: 29.5481\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 22.2821 - val_loss: 29.6552\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 22.3148 - val_loss: 29.7220\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 22.2921 - val_loss: 29.7353\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 22.2184 - val_loss: 29.6728\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 22.2062 - val_loss: 29.5974\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.9825 - val_loss: 29.5991\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 21.9648 - val_loss: 29.5943\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.9373 - val_loss: 29.7495\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 21.8342 - val_loss: 29.9318\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 21.8111 - val_loss: 29.9354\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 21.6692 - val_loss: 29.8846\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.6377 - val_loss: 29.8651\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.5656 - val_loss: 29.7436\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.5043 - val_loss: 29.7027\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.4332 - val_loss: 29.6696\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.4265 - val_loss: 29.6045\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.3515 - val_loss: 29.6382\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 21.3177 - val_loss: 29.7500\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.3204 - val_loss: 29.8788\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.2120 - val_loss: 30.1236\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 21.3448 - val_loss: 30.1713\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.3041 - val_loss: 29.7734\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 21.0916 - val_loss: 29.0577\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 21.2771 - val_loss: 28.5757\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.1676 - val_loss: 28.4276\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 21.1412 - val_loss: 28.3649\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.8803 - val_loss: 28.2809\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 20.8109 - val_loss: 28.1049\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 20.7291 - val_loss: 27.9317\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.7791 - val_loss: 27.9883\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.6712 - val_loss: 28.3943\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 20.7475 - val_loss: 28.4805\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 20.7387 - val_loss: 28.2834\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.6300 - val_loss: 27.7971\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 20.4213 - val_loss: 27.3722\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 20.5710 - val_loss: 27.2120\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 20.4924 - val_loss: 27.4111\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.5085 - val_loss: 27.7304\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 20.3181 - val_loss: 27.5930\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 20.3001 - val_loss: 27.4696\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.2417 - val_loss: 27.5334\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.1476 - val_loss: 27.3698\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 20.1746 - val_loss: 27.0900\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.1604 - val_loss: 26.9844\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 20.1494 - val_loss: 26.8641\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 20.1082 - val_loss: 26.7773\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.1151 - val_loss: 26.6877\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 20.0834 - val_loss: 26.6149\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 20.0250 - val_loss: 26.4455\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.1493 - val_loss: 26.2969\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 20.1044 - val_loss: 26.3831\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.9344 - val_loss: 26.6929\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 19.9349 - val_loss: 26.8931\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 19.9202 - val_loss: 26.7083\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 19.7793 - val_loss: 26.3484\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 20.0525 - val_loss: 26.3382\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.9389 - val_loss: 26.7886\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.7144 - val_loss: 27.1072\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.9125 - val_loss: 27.3091\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.9029 - val_loss: 27.1329\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.7295 - val_loss: 26.7984\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 19.7310 - val_loss: 26.6710\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 19.7029 - val_loss: 26.9056\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 19.5856 - val_loss: 27.3453\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.7261 - val_loss: 27.4582\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 19.8000 - val_loss: 27.3551\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 19.7436 - val_loss: 27.1009\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.6552 - val_loss: 26.9110\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.5659 - val_loss: 26.7819\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 19.5406 - val_loss: 26.6992\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 19.5044 - val_loss: 26.7657\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 19.4796 - val_loss: 26.7275\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.4170 - val_loss: 26.6892\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.4374 - val_loss: 26.7623\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 19.4323 - val_loss: 26.7730\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 19.3224 - val_loss: 26.5897\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 19.3468 - val_loss: 26.3831\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.4613 - val_loss: 26.2059\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.3850 - val_loss: 25.9746\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 19.2172 - val_loss: 25.7606\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 19.3605 - val_loss: 25.7998\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.4094 - val_loss: 26.0743\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.3807 - val_loss: 26.4464\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.2706 - val_loss: 26.8238\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 19.3101 - val_loss: 27.0481\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.4142 - val_loss: 26.8684\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 19.4288 - val_loss: 26.4136\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.3234 - val_loss: 25.8775\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.2759 - val_loss: 25.6241\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 19.2561 - val_loss: 25.7801\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 19.1801 - val_loss: 26.1331\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 19.0144 - val_loss: 26.4073\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.9612 - val_loss: 26.5396\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.0515 - val_loss: 26.3960\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 19.0716 - val_loss: 26.2364\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.9273 - val_loss: 26.0880\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 18.8869 - val_loss: 26.0084\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 18.9089 - val_loss: 25.9899\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.9461 - val_loss: 25.9011\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 18.7361 - val_loss: 25.9550\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 18.9633 - val_loss: 26.0902\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.9735 - val_loss: 26.3860\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 19.0145 - val_loss: 26.6649\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.7585 - val_loss: 26.6236\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.8377 - val_loss: 26.3965\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 18.9986 - val_loss: 26.0883\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 19.0144 - val_loss: 25.8531\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.9167 - val_loss: 25.8394\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.8357 - val_loss: 25.9340\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.7251 - val_loss: 26.2409\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.5949 - val_loss: 26.4701\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 18.5994 - val_loss: 26.5146\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.6025 - val_loss: 26.4542\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.5609 - val_loss: 26.3174\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 18.4469 - val_loss: 26.0262\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 18.4520 - val_loss: 25.7690\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 18.5091 - val_loss: 25.6552\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.5846 - val_loss: 25.6484\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.4199 - val_loss: 25.8181\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.3480 - val_loss: 26.0601\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.3688 - val_loss: 26.2244\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.3283 - val_loss: 26.3208\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 18.4155 - val_loss: 26.4046\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.3725 - val_loss: 26.4623\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 18.2762 - val_loss: 26.3157\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 18.2567 - val_loss: 26.1698\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 18.4338 - val_loss: 26.0984\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.4382 - val_loss: 26.1548\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 18.3302 - val_loss: 26.3720\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.2798 - val_loss: 26.5804\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.1546 - val_loss: 26.5457\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 18.2159 - val_loss: 26.3256\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 18.3781 - val_loss: 26.1160\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.3943 - val_loss: 26.0762\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.2517 - val_loss: 26.1007\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 18.2168 - val_loss: 26.0780\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.0887 - val_loss: 25.9064\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.1467 - val_loss: 25.7359\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.0837 - val_loss: 25.6617\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 18.0685 - val_loss: 25.6663\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.0440 - val_loss: 25.7608\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 17.9508 - val_loss: 25.9146\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.0242 - val_loss: 26.2165\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.8334 - val_loss: 26.3930\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.9151 - val_loss: 26.4273\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.0053 - val_loss: 26.3959\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.9467 - val_loss: 26.1982\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 17.8682 - val_loss: 26.2734\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.8258 - val_loss: 26.4924\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.8069 - val_loss: 26.7265\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.8050 - val_loss: 26.7491\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 17.7780 - val_loss: 26.5996\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.7015 - val_loss: 26.4030\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 17.6511 - val_loss: 26.2341\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.7199 - val_loss: 26.2303\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.7615 - val_loss: 26.4063\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 17.6499 - val_loss: 26.5342\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.7919 - val_loss: 26.5173\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 17.9427 - val_loss: 26.4279\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.8405 - val_loss: 26.3575\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.7267 - val_loss: 26.2738\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 17.5922 - val_loss: 26.2354\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.6513 - val_loss: 26.2515\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.5874 - val_loss: 26.4204\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.5444 - val_loss: 26.4987\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.6066 - val_loss: 26.4415\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.5581 - val_loss: 26.2609\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.4710 - val_loss: 26.1545\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.5877 - val_loss: 26.1381\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 17.5605 - val_loss: 26.1090\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.3999 - val_loss: 26.1544\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.5076 - val_loss: 26.4149\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.4919 - val_loss: 26.5073\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.4396 - val_loss: 26.3160\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.5497 - val_loss: 26.2373\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.4750 - val_loss: 26.1602\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 17.3804 - val_loss: 26.0894\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.4817 - val_loss: 26.1100\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.4481 - val_loss: 26.1948\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.3383 - val_loss: 26.2770\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.1847 - val_loss: 26.3678\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.3045 - val_loss: 26.6390\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.3970 - val_loss: 26.6219\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.2647 - val_loss: 26.4060\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.1759 - val_loss: 26.3315\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.1665 - val_loss: 26.2431\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.1044 - val_loss: 26.1921\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.0397 - val_loss: 26.1395\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.0020 - val_loss: 26.0862\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 17.2656 - val_loss: 26.0877\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.1124 - val_loss: 26.1118\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.0460 - val_loss: 26.1650\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.9603 - val_loss: 26.1487\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.9847 - val_loss: 26.1650\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.9700 - val_loss: 26.1703\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.9079 - val_loss: 26.1911\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.9028 - val_loss: 26.1794\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.8570 - val_loss: 26.1569\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 16.8576 - val_loss: 26.1602\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.9782 - val_loss: 26.1594\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.8361 - val_loss: 26.1703\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.8084 - val_loss: 26.2134\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.8209 - val_loss: 26.2708\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 16.8182 - val_loss: 26.3240\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.8886 - val_loss: 26.3757\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.8722 - val_loss: 26.3643\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.0008 - val_loss: 26.2754\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.9382 - val_loss: 26.2705\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.7770 - val_loss: 26.2625\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.9028 - val_loss: 26.2604\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.9094 - val_loss: 26.2391\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.8909 - val_loss: 26.2122\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.8086 - val_loss: 26.1352\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.7826 - val_loss: 26.1128\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.7639 - val_loss: 25.9753\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.8366 - val_loss: 25.9254\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.0203 - val_loss: 25.9287\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.0259 - val_loss: 25.9375\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.9009 - val_loss: 25.9132\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.7720 - val_loss: 25.9350\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 16.8192 - val_loss: 25.9138\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.8145 - val_loss: 25.9219\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.7809 - val_loss: 25.9705\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.6907 - val_loss: 26.0151\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 16.6706 - val_loss: 26.0341\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.6926 - val_loss: 26.0344\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.5846 - val_loss: 26.0320\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.7743 - val_loss: 26.0534\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.7565 - val_loss: 26.0727\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.7337 - val_loss: 26.1052\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.6788 - val_loss: 26.0940\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.6187 - val_loss: 26.1240\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.6840 - val_loss: 26.1755\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.5335 - val_loss: 26.2063\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.8020 - val_loss: 26.1987\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.8303 - val_loss: 26.1473\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.7187 - val_loss: 26.1075\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.5935 - val_loss: 26.1087\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.5123 - val_loss: 26.1306\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.5178 - val_loss: 26.1367\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.4608 - val_loss: 26.0744\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.5642 - val_loss: 26.0315\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.6011 - val_loss: 26.0024\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.4327 - val_loss: 25.9473\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.4416 - val_loss: 25.9000\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.4323 - val_loss: 25.8658\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.4573 - val_loss: 25.8528\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.5439 - val_loss: 25.8401\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.4357 - val_loss: 25.8263\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.4239 - val_loss: 25.7922\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.4801 - val_loss: 25.7931\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.5126 - val_loss: 25.8097\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.4223 - val_loss: 25.8686\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.3682 - val_loss: 25.9154\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.3664 - val_loss: 25.9651\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.3578 - val_loss: 26.0414\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.3311 - val_loss: 26.0665\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.3611 - val_loss: 26.0973\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.3278 - val_loss: 26.1263\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.3259 - val_loss: 26.1146\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.3089 - val_loss: 26.0831\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.3408 - val_loss: 26.0977\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.2253 - val_loss: 26.1136\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.2375 - val_loss: 26.1103\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 16.2462 - val_loss: 26.1501\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.2487 - val_loss: 26.1684\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.3325 - val_loss: 26.2028\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.4939 - val_loss: 26.2633\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.3681 - val_loss: 26.3055\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.3154 - val_loss: 26.2855\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.2264 - val_loss: 26.2211\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.2519 - val_loss: 26.1303\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.2356 - val_loss: 26.0795\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.1861 - val_loss: 26.0434\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.2538 - val_loss: 26.0048\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.2401 - val_loss: 25.9955\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.2026 - val_loss: 26.0362\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.1835 - val_loss: 26.0683\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.1582 - val_loss: 26.0903\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.2206 - val_loss: 26.0856\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 16.1474 - val_loss: 26.0711\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.2620 - val_loss: 26.0540\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.1696 - val_loss: 26.0263\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.2883 - val_loss: 25.9647\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.1746 - val_loss: 25.8818\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.1941 - val_loss: 25.8505\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 16.2625 - val_loss: 25.8795\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.1044 - val_loss: 25.9580\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.1187 - val_loss: 25.9790\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.1584 - val_loss: 25.9532\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 16.2336 - val_loss: 25.9463\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.1327 - val_loss: 25.9410\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.1836 - val_loss: 25.9055\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.1982 - val_loss: 25.8943\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.0832 - val_loss: 25.8918\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.0241 - val_loss: 25.9193\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.0632 - val_loss: 25.9531\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.1312 - val_loss: 25.9500\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.0838 - val_loss: 25.9189\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.9739 - val_loss: 25.8685\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.0233 - val_loss: 25.8575\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.1349 - val_loss: 25.8688\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 16.1580 - val_loss: 25.8876\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.9944 - val_loss: 25.8971\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.1538 - val_loss: 25.8949\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.2226 - val_loss: 25.8323\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.1415 - val_loss: 25.7381\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.1985 - val_loss: 25.6750\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.1363 - val_loss: 25.6498\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 16.1333 - val_loss: 25.6504\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.1117 - val_loss: 25.7178\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.0748 - val_loss: 25.8267\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.9078 - val_loss: 25.9305\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 16.0549 - val_loss: 26.0040\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.0274 - val_loss: 26.0403\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.8425 - val_loss: 26.0363\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.1674 - val_loss: 26.0261\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.1653 - val_loss: 26.0236\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 16.0002 - val_loss: 25.9947\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.8790 - val_loss: 25.9606\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.8517 - val_loss: 25.9074\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.8632 - val_loss: 25.8697\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.9200 - val_loss: 25.8691\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.8879 - val_loss: 25.8883\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.8104 - val_loss: 25.9270\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.8069 - val_loss: 25.9346\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.7797 - val_loss: 25.9509\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.9044 - val_loss: 25.9383\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.8587 - val_loss: 25.9368\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.7895 - val_loss: 25.9225\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 15.7941 - val_loss: 25.8938\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.0573 - val_loss: 25.8809\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.9757 - val_loss: 25.8980\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.9890 - val_loss: 25.9517\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.9443 - val_loss: 25.9734\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.7779 - val_loss: 26.0061\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8974 - val_loss: 26.0345\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8023 - val_loss: 25.9981\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.8116 - val_loss: 25.9427\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 15.8687 - val_loss: 25.9707\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.8313 - val_loss: 26.0093\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.7467 - val_loss: 26.0138\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.8125 - val_loss: 26.0090\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.7015 - val_loss: 26.0465\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.8383 - val_loss: 26.1374\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.9989 - val_loss: 26.1954\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.7697 - val_loss: 26.2002\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.0293 - val_loss: 26.1591\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.8289 - val_loss: 26.1186\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.6060 - val_loss: 26.0653\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 16.0260 - val_loss: 26.0387\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.0745 - val_loss: 26.0316\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.6770 - val_loss: 26.0364\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.8561 - val_loss: 26.0323\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.2290 - val_loss: 26.0415\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 16.1857 - val_loss: 26.0422\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8089 - val_loss: 26.0317\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.9346 - val_loss: 26.0240\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.1586 - val_loss: 26.0490\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.9960 - val_loss: 26.0836\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 15.6665 - val_loss: 26.0798\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.9822 - val_loss: 26.0641\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 16.0197 - val_loss: 26.0488\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.7963 - val_loss: 26.0146\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.6389 - val_loss: 25.9698\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.7361 - val_loss: 25.9064\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.6381 - val_loss: 25.9098\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.6331 - val_loss: 25.9414\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.5675 - val_loss: 25.9841\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.5556 - val_loss: 26.0290\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.6147 - val_loss: 26.0249\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.5429 - val_loss: 26.0186\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.5733 - val_loss: 26.0243\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.5745 - val_loss: 26.0384\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.6496 - val_loss: 26.0374\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.6570 - val_loss: 25.9991\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.4299 - val_loss: 25.9636\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.6889 - val_loss: 25.9190\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.7217 - val_loss: 25.8935\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.5168 - val_loss: 25.8706\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.8674 - val_loss: 25.8534\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.7687 - val_loss: 25.8492\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.6453 - val_loss: 25.9053\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.5579 - val_loss: 25.9876\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.5692 - val_loss: 26.0571\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.5033 - val_loss: 26.1100\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.4081 - val_loss: 26.1504\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.4641 - val_loss: 26.1644\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.4825 - val_loss: 26.1466\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.3218 - val_loss: 26.1271\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.7084 - val_loss: 26.0910\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.7951 - val_loss: 26.0641\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.6065 - val_loss: 26.0417\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.3773 - val_loss: 26.0264\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 15.6351 - val_loss: 25.9932\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.7855 - val_loss: 25.9389\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8164 - val_loss: 25.8844\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.6584 - val_loss: 25.8196\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.6396 - val_loss: 25.7758\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.5437 - val_loss: 25.7492\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.3949 - val_loss: 25.7484\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.4543 - val_loss: 25.7938\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.5066 - val_loss: 25.8602\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.4474 - val_loss: 25.9061\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.2571 - val_loss: 25.9497\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.4538 - val_loss: 25.9913\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.5668 - val_loss: 25.9964\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.4141 - val_loss: 25.9833\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.3293 - val_loss: 25.9828\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.3460 - val_loss: 26.0246\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.3888 - val_loss: 26.0350\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.3010 - val_loss: 26.0018\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.2460 - val_loss: 25.9520\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.2544 - val_loss: 25.8865\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.2428 - val_loss: 25.8280\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.1891 - val_loss: 25.8071\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.2112 - val_loss: 25.8301\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.2824 - val_loss: 25.8884\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.2030 - val_loss: 25.9300\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.2388 - val_loss: 25.9493\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.1524 - val_loss: 25.9471\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.1275 - val_loss: 25.9487\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.2382 - val_loss: 25.9451\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.1543 - val_loss: 25.9419\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.1163 - val_loss: 25.9617\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.0966 - val_loss: 25.9865\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.1450 - val_loss: 25.9755\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.2156 - val_loss: 25.9152\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 15.0811 - val_loss: 25.8450\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.0610 - val_loss: 25.7910\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.1296 - val_loss: 25.7672\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 15.0074 - val_loss: 25.7544\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.0441 - val_loss: 25.7579\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.0165 - val_loss: 25.7603\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.0616 - val_loss: 25.7679\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.0157 - val_loss: 25.7750\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.0437 - val_loss: 25.8170\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 15.0667 - val_loss: 25.8599\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.1270 - val_loss: 25.9180\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.1394 - val_loss: 25.9673\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.0381 - val_loss: 25.9752\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.0186 - val_loss: 25.9387\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.0745 - val_loss: 25.8660\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.1838 - val_loss: 25.8097\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.2136 - val_loss: 25.7911\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.1887 - val_loss: 25.7953\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.1088 - val_loss: 25.8161\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.0104 - val_loss: 25.8596\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.0464 - val_loss: 25.8956\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.0106 - val_loss: 25.9064\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.1473 - val_loss: 25.8736\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.9872 - val_loss: 25.8665\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.1435 - val_loss: 25.8444\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.3538 - val_loss: 25.8237\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 15.2761 - val_loss: 25.8138\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.1760 - val_loss: 25.8468\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.0375 - val_loss: 25.8845\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.0501 - val_loss: 25.9118\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.9958 - val_loss: 25.9301\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.9868 - val_loss: 25.9388\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.0570 - val_loss: 25.9028\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.1075 - val_loss: 25.8834\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 14.9983 - val_loss: 25.8595\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.8903 - val_loss: 25.8534\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.8980 - val_loss: 25.8719\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 14.8529 - val_loss: 25.8764\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.9773 - val_loss: 25.8474\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.8474 - val_loss: 25.8323\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 15.1093 - val_loss: 25.8475\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 15.4277 - val_loss: 25.8959\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.2068 - val_loss: 25.9374\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.7999 - val_loss: 25.9612\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.0406 - val_loss: 25.9564\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 14.7615 - val_loss: 25.9226\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.2820 - val_loss: 25.8724\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.2477 - val_loss: 25.8139\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.8279 - val_loss: 25.7936\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 14.9096 - val_loss: 25.7657\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.1298 - val_loss: 25.7056\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.9530 - val_loss: 25.6505\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.7081 - val_loss: 25.6317\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.1753 - val_loss: 25.6299\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 15.2934 - val_loss: 25.6051\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.0097 - val_loss: 25.5974\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 14.9960 - val_loss: 25.6133\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.9873 - val_loss: 25.6259\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.9198 - val_loss: 25.5950\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 14.7345 - val_loss: 25.5737\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.8457 - val_loss: 25.6039\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.9215 - val_loss: 25.6710\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.8958 - val_loss: 25.7405\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.7235 - val_loss: 25.8075\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.6936 - val_loss: 25.8677\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.7127 - val_loss: 25.8952\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 14.7256 - val_loss: 25.9057\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.6964 - val_loss: 25.9004\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.6532 - val_loss: 25.9020\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.5923 - val_loss: 25.8758\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.7654 - val_loss: 25.8260\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.8054 - val_loss: 25.7704\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 14.5988 - val_loss: 25.7238\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.8705 - val_loss: 25.6939\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.5543 - val_loss: 25.6549\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.9502 - val_loss: 25.6229\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.1420 - val_loss: 25.6141\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.8298 - val_loss: 25.6524\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.7136 - val_loss: 25.7177\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.9245 - val_loss: 25.7634\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.7267 - val_loss: 25.7803\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.5664 - val_loss: 25.7577\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.9022 - val_loss: 25.7046\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.9021 - val_loss: 25.6506\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 14.6390 - val_loss: 25.5937\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.7496 - val_loss: 25.5916\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.7532 - val_loss: 25.6095\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.6644 - val_loss: 25.6486\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.6088 - val_loss: 25.7033\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 14.5457 - val_loss: 25.7322\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.5562 - val_loss: 25.7432\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.5689 - val_loss: 25.7549\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.5750 - val_loss: 25.7738\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 14.4584 - val_loss: 25.7660\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.8105 - val_loss: 25.7691\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.7436 - val_loss: 25.7899\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 14.5672 - val_loss: 25.8349\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 14.4666 - val_loss: 25.8829\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.4632 - val_loss: 25.9286\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.3893 - val_loss: 25.9690\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.4360 - val_loss: 25.9584\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.5398 - val_loss: 25.9144\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.4529 - val_loss: 25.8587\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.3615 - val_loss: 25.8132\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.6627 - val_loss: 25.7702\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.5363 - val_loss: 25.7690\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.4929 - val_loss: 25.8051\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.6945 - val_loss: 25.8378\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14.5533 - val_loss: 25.8344\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.4903 - val_loss: 25.8444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb56d449b10>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o1 = model.predict(campusx_input.reshape(1,4))\n",
        "o1 = o1[0][0]\n",
        "o1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9cEYmEKec3X",
        "outputId": "a8b8459a-2fc5-4cc4-eb7d-e18938883e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.894424"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_input,y)\n",
        "\n",
        "o2 = rf.predict(campusx_input.reshape(1,4))\n",
        "o2 = o2[0]\n",
        "o2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3wAZkXmfuLn",
        "outputId": "5a7349d4-5409-453d-ed46-d8fbcde329ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.78900000000001"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xg = XGBRegressor()\n",
        "xg.fit(X_input,y)\n",
        "o3 = xg.predict(campusx_input.reshape(1,4))\n",
        "o3 = o3[0]\n",
        "o3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coA3K11rg6x_",
        "outputId": "56d155c4-b6cd-4ba8-d4c4-e3b1ca50bfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19:40:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.60675"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "lr = SVR()\n",
        "lr.fit(X_input,y)\n",
        "o4 = lr.predict(campusx_input.reshape(1,4))\n",
        "o4 = o4[0]\n",
        "o4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "comYZApahAzb",
        "outputId": "dbecd0e2-d175-4676-f28b-fec379f2f3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.87337894659072"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "rf = GradientBoostingRegressor()\n",
        "rf.fit(X_input,y)\n",
        "\n",
        "o5 = rf.predict(campusx_input.reshape(1,4))\n",
        "o5 = o5[0]\n",
        "o5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi_8PkhZhEgP",
        "outputId": "ae7da76f-1790-4d46-d3ed-763579173f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.95256049532265"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "rf = KNeighborsRegressor()\n",
        "rf.fit(X_input,y)\n",
        "\n",
        "o6 = rf.predict(campusx_input.reshape(1,4))\n",
        "o6 = o6[0]\n",
        "o6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9P-m4rGhKT3",
        "outputId": "b1d8174f-8c84-4452-a227-e41f55029836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.516000000000005"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(o1+o2+o3+o4+o5+o6)/6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH5sik3NhSZ3",
        "outputId": "35682d6c-250c-4442-e3b4-76f476e32c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.10535239477853"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wNCv8RVDjF4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}